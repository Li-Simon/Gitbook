# 模型评估

这一章主要介绍一些模型评估的方法，比如Cross-Validation, ROC, AUC  
模型的性能[^1]：  
1. 错误率/精度（accuracy）  
2. 准确率（查准率，precision）/召回率（查全率，recall）  
3. P-R曲线，F1度量  
4. ROC曲线/AUC（最常用）  
5. 代价曲线

### 错误率/精度（accuracy）

假设我们拥有m个样本个体，那么该样本的错误率为：  
  $$e = \frac{1}{m}\sum_{i=1}^{m}I(f(x_i) \neq y_i)$$  
或者：  
  $$e = \int_{x \sim D}I(f(x) \neq y)p(x)dx$$

### 准确率/召回率（查全率）

  $$准确率=\frac{预测为真且实际也为真的个体个数}{预测为真的个体个数}$$  
  $$召回率 = \frac{预测为真且实际也为真的个体个数}{实际为真的个体个数}$$  
 我们将准确率记为P，召回率记为R，定义，TP\(true positive\)，FP\(false positive\)，FN\(false negative\)，TN\(true negative\)。则有：  
   $$P = \frac{TP}{TP+FP}$$  
   $$R = \frac{TP}{TP+FN}$$

### ROC曲线/AUC

ROC曲线则是以假正例率FPR为横轴，真正例率TPR为纵轴。其中  
  $$FPR = \frac{FP}{FP+TN}$$  
  $$TPR=\frac{TP}{TP+FN}$$  
我们可以看到真正例率与召回率是一样的，那么ROC曲线图如下图所示：

[^1]: [机器学习模型性能评估方法笔记](https://blog.csdn.net/batuwuhanpei/article/details/51884351)

