#机器学习问题

1. 过拟合与欠拟合，交差验证的目的，超参数搜索方法，EarlyStopping
2. L1正则和L2正则的做法，正则化背后的思想，BatchNorm，Covariance Shift, L1正则产生稀疏解的原理
3. 逻辑回归为何是线性模型，LR如何解决低维不可分，从图模型角度看LR，
4. 和朴素贝叶斯和无监督
5. 几种参数估计方法MLE，MAP，贝叶斯的联系与区别
6. 简单说下SVM的支持向量，KKT，何为对偶，核的通俗理解
7. GBDT,随机森林能否并行，问问bagging, boosting
8. 生成模型，判别模型举个例子
9. 聚类方法的掌握，问问kmeans的EM推导思路，谱聚类和Grapg-cut的理解
10. 梯度下降类方法和牛顿类方法的区别，随便问问Adam，L-BFGS的思路
11. 半监督的思想，问问一些特定半监督算法是如何利用无标签数据的，从MAP角度看半监督
12. 常见的分类模型的评价指标\(顺便问问交叉熵，ROC如何绘制，AUC的物理含义，类别不均匀样本\)

神经网络

1. CNN中卷积操作和卷积核作用，maxpooling作用
2. 卷积层与全连接层的联系
3. 梯度爆炸与消失的概念\(顺便问问神经网络权重初始化的方法，为何能减缓梯度爆炸与消失，CNN中有哪些解决方法，LSTM如何解决的，如何梯度裁剪，dropout如何用在RNN系列网络中，dropout如何防止过拟合\)
4. 为何卷积可以用在图像，语音，语句上，顺便问问channel在不同类型数据源中的含义

自然语言处理，推荐系统

1. CRF跟逻辑回归，最大熵模型的关系
2. CRF的优化方法，CRF和MRF的联系，HMM与CRF的关系\(顺便问问朴素贝叶斯和HMM的联系，LSTM+CRF用于序列标注的原理，CRF的点函数和边函数，CRF的经验分布\)
3. wordEmbedding的几种常用方法和原理\(language model,perplexity评价指标，word2vec跟Glove的异同\)
4. Topic model说一说，为何CNN能用在文本分类，syntactic 和semantic问题举例，
5. 常见的sentence embedding方法，注意力机制\(注意力机制的几种不同情形，为何引入，seq2seq原理\)
6. 序列标注的评价指标，语义消歧的做法，常见的跟word有关的特征
7. factorizatuon machine,常见矩阵分解模型
8. 如何把分类模型用于商品推荐\(包括数据集划分，模型验证等\)
9. 序列学习，wide
   &
   deep model\(顺便问问为何wide和deep\)

  


