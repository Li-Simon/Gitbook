# 核函数方法

### 引入核函数

其实在我们求解对偶问题的最优化问题时，我们只需要求$$\mathbf{x_ix_j}$$,因此如果存在一种变换，使得：  
&emsp;&emsp;$$ \mathbf{x} \to \phi(\mathbf{x} )$$  
且  
&emsp;&emsp;$$ \mathbf{x_ix_j}\to \phi(\mathbf{x_i})\phi(\mathbf{x_j}) = K(\mathbf{x_i,x_j})$$  
其实我们不需要显示的给出$$\phi(\mathbf{x})$$的表达式，只需要知道$$K(\mathbf{x_i,x_j})$$就可以了，$$K(\mathbf{x_i,x_j})$$就是核函数。  
引入核函数，是因为我们可以利用核函数方法来解决非线性分类问题。

### 正定核函数

#### 正定核的充要条件

设K:\(X,X\)-&gt;R上的对称函数，则K\(x,z\)为正定核函数的充要条件是对任意$$x_i \in X$$,i=1,2,...,m,K\(x,z\)对应的Gram矩阵：  
&emsp;&emsp;$$K =[K(x_i,x_j)]_{mXm}$$  
的半正定矩阵。

### 常用的核函数

1. 线性核：$$K(\mathbf{x,z}) = \mathbf{x_i^Tx_j}$$     
2. 多项式核函数：$$K(\mathbf{x,z}) = (\mathbf{xz}+1)^p $$       

分类决策函数是：  
&emsp;&emsp;$$f(\mathbf{x}) = sign(\displaystyle \sum_{i=1}^N \alpha_i^*y_i(\mathbf{x_ix}+1)^p +b^*) $$   
3. 高斯核函数  
&emsp;&emsp;$$K(\mathbf{x,z}) = \exp(-\frac{||\mathbf{x-z}||^2}{2\sigma^2}) $$   
   分类决策函数是：  
&emsp;&emsp;$$f(\mathbf{x}) = sign(\displaystyle \sum_{i=1}^N \alpha_i^*y_i\exp(-\frac{||\mathbf{x-z}||^2}{2\sigma^2}) +b^*) $$  
4. 拉普拉斯核函数  
&emsp;&emsp;$$K(\mathbf{x,z}) = \exp(-\frac{||\mathbf{x-z}||}{\sigma}) $$  $$\sigma > 0$$ 
5. Sigmoid核函数  
&emsp;&emsp;$$K(\mathbf{x_i,x_j}) = \tanh(\mathbf{x_i^Tx_j} + \theta) $$  $$\beta > 0,\theta < 0$$ 

### 非线性分类问题

输入：训练数据$$(x_i, y_i), i=1,2...N, y_i \in {+1, -1}, x_i \in R^m$$  
输出：分类决策函数  
\(1\)选择适合的核函数K\(x,z\)和适当的参数C，构造并求解优化问题：  
&emsp;&emsp;$$\displaystyle \min_{\mathbf{\alpha}}\frac{1}{2}\displaystyle \sum_{i=1}^N\displaystyle \sum_{j=1}^N\alpha_i\alpha_jy_iy_jK(\mathbf{x_i,x_j}) - \displaystyle \sum_{i=1}^N \alpha_i$$  
&emsp;&emsp;s.t. $$\sum_{i=1}^N \alpha_iy_i = 0$$  
&emsp;&emsp;$$0 \le \alpha_i \le C$$ ,i=1,2,...,N.   
求得最优解$$\mathbf{\alpha^*} = (\alpha_1^*,\alpha_2^*,...,\alpha_N^*)^T$$：  
\(2\)选择一个指标j使得$$0 <  \alpha_j < C$$，计算   
&emsp;&emsp;$$ b^* = y_j - \displaystyle \sum_{i=1}^N \alpha_i^*y_iK(\mathbf{x_i,x_j})$$  
\(3\)构造分类决策函数:  
&emsp;&emsp;$$f(x) = sign(\displaystyle \sum_{i=1}^N \alpha_i^*y_iK(\mathbf{x_i,x_j}) + b^*) $$

