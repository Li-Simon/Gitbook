#先验与算法设计
这一节是目的是总结怎么通过先验来设计算法。根据“没有免费午餐定理”我们知道，不存在一个普适的算法在所有场合下都表现很好，因此我们必须根据样本的先验知识来选择模型与设计算法。因此，我们到底该怎么设计我们的算法，也就是基于不同的问题背景，得出先验知识，然后把先验知识作为我们设计算法的基本条件。我们首先要分析的是一些比较成功的网络，比如CNN，RNN，可能还有一些机器学习模型；分析它怎么利用起了先验知识而获得了相比于其它模型更好的成果。因此，这节的核心是先验与算法设计。最终的目的是通过分析已有的成功经验，借鉴这些经验而把它用在未来的问题上面去，也就是《论语》中的"告诸往而知来"。  
### NO FREE LUNCH
没有免费的午餐定理：没有一个模型是对所有的样本是最优的。  
比如下面的例子：  
![](/assets/NO_FREE_LUNCH.png)  
黑点是训练样本，白点是测试样本点。根据训练样本，我们得到模型A，B。如果测试点不同，则A，B的相对表现不同。问题的关键在于，我们先验的假设了\(测试\)样本点在所有空间是均匀分布的，因此，在训练集上训练出的所有模型的效果是一样的，因为你总有样本集是落在你模型预测的曲线之上的。  
因此，如果样本点在整个数据空间是均匀分布的前提下，则不存在一个模型或算法在所有问题上比其它算法更优越。  
但是现实遇到的问题是，数据的分布是受限制的，数据存在一个先验分布，因此会存在一些模型比其它模型更有效。这里NFL不再有是因为问题的前提--数据是均匀分布的--不再成立。因此，脱离场景谈方法是无效的，我们只能针对特定的问题，寻找最佳的优化方法。

### 正则化

没有免费的午餐定理告诉我们没有一个模型是对所有的样本是最优的[^1]，因此，对于特定的样本，我们需要把先验加进模型中\(也就是损失函数中\)，这个先验就是我们对这个样本的知识，比如样本数据的分布，样本的均值或者方差等\(统计物理学中的系统的能量可以看成一种均值，统计物理学中有很多启发性的模型\)。加到模型中的就是我们的正则项，正则项就是一个先验，是我们需要模型满足的约束。  
一个问题是，正则化只能使我们的模型更稳定，不会更精确，那先验怎么作为正则化的形式加进模型，使得我们的模型更优越呢？  

###一些技术
这里，有些是技术，有些是先验知识，但更多的是先验知识。   
1. 误差反向传播，梯度下降方法
2. 梯度消失：Relu, leak-Relu
3. 循环网络，矩阵相乘与梯度爆炸： 
4. Pooling：特性提取，几何变换不变性  
5. Dropout与Bagging：  
6. 正则化  
7. 卷积  
8. 批量归一化与泛化能力  

##如何设计一个卷积神经网络来实现图像分类
####BP网络
在本章第一节，我们介绍了如何实现一个误差反向的神经网络。因此，我们可以把一张图转化为一个向量，输入到BP网络中，再根据总的类别来设置输出向量的长度，比如1000个分类就让输出的维度是1000.这样我们可以实现一个很简单的用于图像分类的神经网络。    
当然这只是一个很粗浅的模型，因为它没有利用到图像固有的一些特性，或者说图像识别这个问题背后的先验知识。

####先验与熵值
#####卷积[^1]
全连接认为下层的输出与上层的所有元素都有关系，上层的每个元素的作用是均等的。而卷积操作，基于这样一个假设，网络下一层的元素只与上一层网络的部分元素有关。这相当于全连接来说，卷积相当于加了一个矩形窗，这是一个很强的先验。但正是由于有这个先验，使得我们的计算量远远小于全连接网络。  
卷积导致了参数共享，而参数共享的先验就是平移不变性。  
#####池化

[^1]: 《深度学习》9.6节



