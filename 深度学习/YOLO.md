## YOLO

目标检测算法可以分为two stage与one stage两类算法：  
two stage就是先产生region proposal，再在region proposal上做分类与回归，典型的就是RCNN的算法，如：R-CNN, Fast R-CNN, Faster R-CNN, 它的优点是准确率高，但是速度慢。  
one stage算法仅仅使用一个CNN网络直接预测不同目标的类别与位置，典型的算法是YOLO，SSD。 它的准确度要低一些，但是它的速度快。  
目标检测的一个实际应用场景就是无人驾驶，如果能够在无人车上装载一个有效的目标检测系统，那么无人车将和人一样有了眼睛，可以快速地检测出前面的行人与车辆，从而作出实时决策[^1]。

### YOLO的原理图

![](/assets/YOLO_Principle.png)

#### 原理解析

整体上，YOLO采用的是一个单独的CNN实现end-to-end的目标检测。通过输入一张448x448的图片到CNN，先经过GoogLeNet的前二十个卷积层，再通过一些卷积层与两个全连接层，最终输出的是7x7x30的张量。7x7表示49个区域，30=20+2x5，表示二十个类别的概率，2表示两个边界框，5表示每个边界框的四个坐标以及一个置信度。



##### 输出参数解析

每个单元格需要预测$$(B\times5+C)$$个值。如果将输入图片划分为 $$S\times S$$ 网格，那么最终预测值为$$ S\times S\times (B\times5+C)$$ 大小的张量。整个模型的预测值结构如下图所示。对于PASCAL VOC数据，其共有20个类别，如果使用 S=7,B=2 ，那么最终的预测结果就是$$ 7\times 7\times 30 $$大小的张量。在下面的网络结构中我们会详细讲述每个单元格的预测值的分布位置。

#### 损失函数  
Yolo算法将目标检测看成回归问题，所以采用的是均方差损失函数。但是对不同的部分采用了不同的权重值。首先区分定位误差和分类误差。  
对于定位误差，即边界框坐标预测误差，采用较大的权重 $$\lambda_{coord}=5$$。    
然后其区分不包含目标的边界框与含有目标的边界框的置信度，对于前者，采用较小的权重值 $$\lambda_{noobj}=0.5 $$。其它权重值均设为1。  然后采用均方误差，其同等对待大小不同的边界框，但是实际上较小的边界框的坐标误差应该要比较大的边界框要更敏感。为了保证这一点，将网络的边界框的宽与高预测改为对其平方根的预测，即预测值变为 $$(x,y,\sqrt{w}, \sqrt{h})$$ 。
最终的损失函数：    
![](/assets/YOLO_Cost_Function.png)    

上面两行是坐标误差，中间两行是IOU误差，最下面一行是分类误差。   
其中第一项是边界框中心坐标的误差项， $$1^{obj}_{ij}$$指的是第 i 个单元格存在目标，且该单元格中的第  j 个边界框负责预测该目标。第二项是边界框的高与宽的误差项。第三项是包含目标的边界框的置信度误差项。第四项是不包含目标的边界框的置信度误差项。而最后一项是包含目标的单元格的分类误差项， $$1^{obj}_{i}$$ 指的是第 i 个单元格存在目标。这里特别说一下置信度的target值 $$C_i$$ ，如果是不存在目标，此时由于 Pr(object)=0，那么 $$C_i=0$$ 。如果存在目标， Pr(object)=1 ，此时需要确定 $$\text{IOU}^{truth}_{pred}$$ ，当然你希望最好的话，可以将IOU取1，这样 $$C_i=1$$ ，但是在YOLO实现中，使用了一个控制参数rescore（默认为1），当其为1时，IOU不是设置为1，而就是计算truth和pred之间的真实IOU。不过很多复现YOLO的项目还是取 $$C_i=1$$ ，这个差异应该不会太影响结果吧。   

 ##### 输出参数解析

具体来说，Yolo的CNN网络将输入的图片分割成 $$S\times S$$ 网格，然后每个单元格负责去检测那些中心点落在该格子内的目标，如图6所示，可以看到狗这个目标的中心落在左下角一个单元格内，那么该单元格负责预测这个狗。每个单元格会预测 B 个边界框（bounding box）以及边界框的置信度（confidence score）。所谓置信度其实包含两个方面，一是这个边界框含有目标的可能性大小，二是这个边界框的准确度。前者记为 Pr\(object\) ，当该边界框是背景时（即不包含目标），此时 Pr\(object\)=0 。而当该边界框包含目标时， Pr\(object\)=1 。边界框的准确度可以用预测框与实际框（ground truth）的IOU（intersection over union，交并比）来表征，记为 $$\text{IOU}^{truth}_{pred}$$ 。因此置信度可以定义为 $$Pr(object)*\text{IOU}^{truth}_{pred}$$ 。很多人可能将Yolo的置信度看成边界框是否含有目标的概率，但是其实它是两个因子的乘积，预测框的准确度也反映在里面。边界框的大小与位置可以用4个值来表征： \(x, y,w,h\) ，其中 \(x,y\) 是边界框的中心坐标，而 w 和 h 是边界框的宽与高。还有一点要注意，中心坐标的预测值 \(x,y\) 是相对于每个单元格左上角坐标点的偏移值，并且单位是相对于单元格大小的，单元格的坐标定义如图6所示。而边界框的 w 和 h 预测值是相对于整个图片的宽与高的比例，这样理论上4个元素的大小应该在 \[0,1\] 范围。这样，每个边界框的预测值实际上包含5个元素： \(x,y,w,h,c\) ，其中前4个表征边界框的大小与位置，而最后一个值是置信度。

 

[^1]:  目标检测\|YOLO原理与实现  [https://zhuanlan.zhihu.com/p/32525231](https://zhuanlan.zhihu.com/p/32525231)

