# 模型评估

这一章主要介绍一些模型评估的方法，比如Cross-Validation, ROC, AUC  
模型的性能[^1]：  
1. 错误率/精度（accuracy）  
2. 准确率（查准率，precision）/召回率（查全率，recall）  
3. P-R曲线，F1度量  
4. ROC曲线/AUC（最常用） 
参考这篇文章：[机器学习模型性能评估方法笔记](https://blog.csdn.net/batuwuhanpei/article/details/51884351)
### 错误率/精度（accuracy）

假设我们拥有m个样本个体，那么该样本的错误率为：  
&emsp;&emsp; $$e = \frac{1}{m}\sum_{i=1}^{m}I(f(x_i) \neq y_i)$$  
或者：  
&emsp;&emsp; $$e = \int_{x \sim D}I(f(x) \neq y)p(x)dx$$

### 准确率/召回率（查全率）

&emsp;&emsp;准确率=预测为真且实际也为真的个体个数 / 预测为真的个体个数    
&emsp;&emsp;召回率 = 预测为真且实际也为真的个体个数 / 实际为真的个体个数      
 我们将准确率记为P，召回率记为R，定义，TP\(true positive\)，FP\(false positive\)，FN\(false negative\)，TN\(true negative\)。则有：  
&emsp;&emsp; $$P = \frac{TP}{TP+FP}$$  
&emsp;&emsp; $$R = \frac{TP}{TP+FN}$$

### ROC曲线/AUC

ROC曲线则是以假正例率FPR为横轴，真正例率TPR为纵轴。其中  
&emsp;&emsp;$$FPR = \frac{FP}{FP+TN}$$  
&emsp;&emsp;$$TPR=\frac{TP}{TP+FN}$$  
我们可以看到真正例率与召回率是一样的，那么ROC曲线图如下图所示：

[^1]: [机器学习模型性能评估方法笔记](https://blog.csdn.net/batuwuhanpei/article/details/51884351)

