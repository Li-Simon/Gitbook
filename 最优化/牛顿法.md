# 牛顿法和拟牛顿法（Newton's method &Quasi-Newton methods）

1\)牛顿法（Newton's method）  
牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f \(x\)的泰勒级数的前面几项来寻找方程f \(x\) = 0的根。牛顿法最大的特点就在于它的收敛速度很快。[^1]  
步骤：  
首先，选择一个接近函数f\(x\)零点的$$x_{0}$$,计算相应的计算相应的 $$f(x_0)$$ 和切线斜率$$f'(x_0)$$。然后计算穿过点$$(x_0, f(x_0))$$并且斜率为$$f'(x_0)$$的直线和x轴的交点的x轴坐标，也就是如下方程：  
$$\kern{4 em} x*f'(x_{0}) + f(x_0) -x_{0}*f'(x_0) = 0$$  
我们将新求得的点的 x 坐标命名为$$x_{1}$$，通常$$x_{1}$$会比$$x_{0}$$更接近方程$$f(x)=0$$的解。因此我们现在可以利用$$x_{1}$$开始下一轮迭代。迭代公式可化简为如下所示：  
$$\kern{4 em} x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$$  
$$\kern{4 em} \mathbf{X_{n+1}} = \mathbf{X_{n}} - \frac{1}{1}$$  
如果X是向量，则可以写成向量形式：  
　已经证明，如果$$f'(x)$$是连续的，并且待求的零点x是孤立的，那么在零点x周围存在一个区域，只要初始值$$x_{0}$$位于这个邻近区域内，那么牛顿法必定收敛。 并且，如果$$f'(x)$$不为0, 那么牛顿法将具有平方收敛的性能. 粗略的说，这意味着每迭代一次，牛顿法结果的有效数字将增加一倍。下图为一个牛顿法执行过程的例子。

![](/assets/Algo_NewtonMethods1.png)

**关于牛顿法和梯度下降法的效率对比：**

**从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）**

**根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。**

![](/assets/Algo_NewtonMethods2.png)

注：红色的牛顿法的迭代路径，绿色的是梯度下降法的迭代路径。

**牛顿法的优缺点总结：**

**优点：二阶收敛，收敛速度快；**

**缺点：牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。**

2）拟牛顿法（Quasi-Newton Methods）

拟牛顿法是求解非线性优化问题最有效的方法之一，于20世纪50年代由美国Argonne国家实验室的物理学家W.C.Davidon所提出来。Davidon设计的这种算法在当时看来是非线性优化领域最具创造性的发明之一。不久R. Fletcher和M. J. D. Powell证实了这种新的算法远比其他方法快速和可靠，使得非线性优化这门学科在一夜之间突飞猛进。

拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。  
　　具体步骤：  
　　拟牛顿法的基本思想如下。首先构造目标函数在当前迭代$$x_k$$的二次模型：  
$$\kern{4 em} m_k(p) = f(x_k) + \bigtriangledown f(x_k)^Tp + \frac{p^TB_{k}p}{2}$$  
$$\kern{4 em} p_k = - B^{-1}_{k}\bigtriangledown f(x_k)$$  
这里$$B_k$$是一个对称正定矩阵，于是我们取这个二次模型的最优解作为搜索方向，并且得到新的迭代点：  
$$\kern{4 em} x_{k+1} = x_{k} + \alpha_kp_k$$  
其中我们要求步长$$\alpha_k$$满足Wolfe条件。这样的迭代与牛顿法类似，区别就在于用近似的Hesse矩阵$$B_k$$ 代替真实的Hesse矩阵。所以拟牛顿法最关键的地方就是每一步迭代中矩阵Bk 的更新。现在假设得到一个新的迭代$$x_k+1$$，并得到一个新的二次模型：

这个公式被称为割线方程。常用的拟牛顿法有DFP算法和BFGS算法。  
[最优化方法：牛顿迭代法和拟牛顿迭代法](https://blog.csdn.net/pipisorry/article/details/24574293)

