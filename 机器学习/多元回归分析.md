# 多元回归分析

多元回归方程  
$$\hat y = \lambda_{0} + \lambda_{1}x_{1}+\lambda_{2}x_{2}+...+\lambda_{m}x_{m}$$  
其中$$b_j$$是$$x_j$$的偏回归系数，$$\hat y$$是样本的估计值。  
根据最小值原理，可以求得偏回归系数。  
$$L(b) = \sum_{i=0}^{n-1}[y_i-(\lambda_{0} + \lambda_{1}x_{1i}+\lambda_{2}x_{2i}+...+\lambda_{m}x_{mi})]^2$$  
变量数为m,样本数为n. 最小二乘法的目的就是找到一组偏回归系数使得损失函数L极小，极端情况就是L=0，则所有样本估计值就是样本的观测值。这只在满秩的情况下存在。一般只是求得L的极小值点。对损失函数求偏导，可以得到：

实际问题可以转化成矩阵分析  
$$\begin{bmatrix}x_{11}&x_{12}&\cdots&x_{1m}&1
\\ x_{21}&x_{22}&\cdots&x_{2m}&1
\\\cdots&\cdots&\cdots&\cdots&\cdots
\\x_{n1}&x_{n2}&\cdots&x_{nm}&1
\end{bmatrix}
\begin{bmatrix} \lambda_1\\ \lambda_2\\\cdots\\\lambda_n\\\lambda_0\end{bmatrix}=\begin{bmatrix} y_{1o}\\ y_{2o}\\\cdots\\y_{no}\end{bmatrix} + \begin{bmatrix} \epsilon_{1}\\ \epsilon_{2o}\\\cdots\\\epsilon_{no}\end{bmatrix} $$  
即：  
$$X*\lambda = Y + \epsilon$$  
寻找一组$$\lambda$$使得:$$L(\lambda) = (X*\lambda - Y)^T(X*\lambda - Y)$$极小  
利用$$L(\lambda)$$对向量$$\lambda$$[求导](https://zhuanlan.zhihu.com/p/24709748)可以得到[^1]：  
$$\frac{\partial L(\lambda)}{\partial \lambda} = 2X^T(X\lambda -Y) = 0$$  
我们也可以得到：
$$\frac{\partial^2 L(\lambda)}{\partial \lambda^2} = 2X^TX$$  
求得：$$\lambda = (X^TX)^{-1}X^TY$$  
$$(X^TX)^{-1}X^T$$也称为X的伪逆。

#多项式拟合
函数的多项式表示方式：
$$y = \sum_{k=0}^{m}\lambda_{k}x^{k}$$
对于n组数据$$(x_i,y_i)$$若我们想用多项式去拟合这组数据，就是寻找使下列函数值极小的一组系数$$\lambda$$
$$L(\lambda) = \frac{1}{2m}\sum_{i=0}^{n-1}(y_i - \sum_{k=0}^{m}\lambda_{k}x_{i}^{k})^2$$
令：
$$\lambda = [\lambda_0,\lambda_1,\cdots,\lambda_m]^T$$
$$X_i = [x_{i}^{0},x_{i}^{1},\cdots,x_{i}^{m}]$$
$$Y = [Y_0,Y_1,\cdots,Y_{n-1}]^T$$

则上面损失函数可以表示为：
$$L(\lambda) = (X*\lambda - Y)^T(X*\lambda - Y)$$

对其求一阶导，结果为0；
$$\frac{\partial L(\lambda)}{\partial \lambda} = 0$$
最终方程可以化简成如下形式：

$$\begin{bmatrix}\sum_{j=0}^{n-1}x_j^{0}&\sum_{j=0}^{n-1}x_j^{1}&\cdots&\sum_{j=0}^{n-1}x_j^{m}
\\ \sum_{j=0}^{n-1}x_j^{1}&\sum_{j=0}^{n-1}x_j^{2}&\cdots&\sum_{j=0}^{n-1}x_j^{m+1}
\\\cdots&\cdots&\cdots&\cdots
\\\sum_{j=0}^{n-1}x_j^{m}&\sum_{j=0}^{n-1}x_j^{m+1}&\cdots&\sum_{j=0}^{n-1}x_j^{2m}
\end{bmatrix}
\begin{bmatrix} \lambda_0\\ \lambda_1\\\cdots\\\lambda_m\end{bmatrix}=\begin{bmatrix} \sum_{j=0}^{n-1}y_j*x_j^{0}\\ \sum_{j=0}^{n-1}y_j*x_j^{1}\\\cdots\\\sum_{j=0}^{n-1}y_j*x_j^{m}\end{bmatrix}$$ 
即:$$X*\lambda = Y$$ 得到 $$\lambda = X^{-1}Y$$
若在方程上加上一个正则项，
$$L(\lambda) = \frac{1}{2m}\sum_{i=0}^{n-1}(y_i - \sum_{k=0}^{m}\lambda_{k}x_{i}^{k})^2 + \sum_{k=0}^{m}\lambda_{k}^{2}$$
得到如下的矩阵：

$$\begin{bmatrix}\sum_{j=0}^{n-1}x_j^{0} - 2n&\sum_{j=0}^{n-1}x_j^{1}&\cdots&\sum_{j=0}^{n-1}x_j^{m}
\\ \sum_{j=0}^{n-1}x_j^{1}&\sum_{j=0}^{n-1}x_j^{2} - 2n&\cdots&\sum_{j=0}^{n-1}x_j^{m+1}
\\\cdots&\cdots&\cdots&\cdots
\\\sum_{j=0}^{n-1}x_j^{m}&\sum_{j=0}^{n-1}x_j^{m+1}&\cdots&\sum_{j=0}^{n-1}x_j^{2m}-2n
\end{bmatrix}
\begin{bmatrix} \lambda_0\\ \lambda_1\\\cdots\\\lambda_m\end{bmatrix}=\begin{bmatrix} \sum_{j=0}^{n-1}y_j*x_j^{0}\\ \sum_{j=0}^{n-1}y_j*x_j^{1}\\\cdots\\\sum_{j=0}^{n-1}y_j*x_j^{m}\end{bmatrix}$$ 

类似于Ridge回归：
但是对于加噪声参数的多项式数据，发现不加正则项能给出正确的结果，加正则项反倒不能。

#迭代法求解
求解上面的方程也可以使用迭代法求解：



[^1]: 矩阵求导术（上），https://zhuanlan.zhihu.com/p/24709748

