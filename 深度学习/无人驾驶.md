# 无人驾驶

无人驾驶的主要内容：

1. 传感：通过雷达，激光，摄像头，GPS以及各种传感器来收集数据
2. 感知：通过传感收集的数据进行处理
   1. 定位
   2. 物体识别与跟踪
3. 决策：基于数据做出决策
   1. 行为预测
   2. 路径规划
   3. 避障

## 感知

### 物体识别

无人驾驶，首先就是就是定位问题，要知道自己在哪儿，让自己处于安全的区域内，因此，首先就是需要检测马路上的斑马线。

#### 线检测

##### Hough变换

直线检测最经典的方法就是Hough变换，Hough变换在图像处理那一章节已经介绍了，因此这笔不介绍原理了。主要介绍OpenCV中的HoughLinesP函数：  
C++: void HoughLinesP\(InputArray image, OutputArray lines, double rho, double theta, int threshold, double minLineLength=0, double maxLineGap=0 \)  
Parameters:  
image – 8-bit, single-channel binary source image. The image may be modified by the function.  
lines – Output vector of lines. Each line is represented by a 4-element vector  \($$x_1, y_1, x_2, y_2$$\) , where  $$(x_1,y_1)$$ and  $$(x_2, y_2)$$ are the ending points of each detected line segment.  
rho – Distance resolution of the accumulator in pixels.  
theta – Angle resolution of the accumulator in radians.  
threshold – Accumulator threshold parameter. Only those lines are returned that get enough votes \( &gt;hreshold\).  
minLineLength – Minimum line length. Line segments shorter than that are rejected.  
maxLineGap – Maximum allowed gap between points on the same line to link them.  
例子：  
rho = 2  \# distance resolution in pixels of the Hough grid  
theta = np.pi / 180  \# angular resolution in radians of the Hough grid  
threshold = 12  \# minimum number of votes \(intersections in Hough grid cell\)  
min\_line\_length = 200  \# minimum number of pixels making up a line  
max\_line\_gap = 200  \# maximum gap in pixels between connectable line segments

##### Canny edge dector

C++: void Canny\(InputArray image, OutputArray edges, double threshold1, double threshold2, int apertureSize=3, bool L2gradient=false\)  
Parameters:  
image – single-channel 8-bit input image.  
edges – output edge map; it has the same size and type as image.  
threshold1 – first threshold for the hysteresis procedure.  
threshold2 – second threshold for the hysteresis procedure.  
apertureSize – aperture size for the Sobel\(\) operator.  
L2gradient – a flag, indicating whether a more accurate  $$L_2 norm  =\sqrt{(dI/dx)^2 + (dI/dy)^2}$$ should be used to calculate the image gradient magnitude \( L2gradient=true \), or whether the default  $$ L_1 norm  =|dI/dx|+|dI/dy|  $$is enough \( L2gradient=false \).

#### Distortion 与 Calibrating Camera

![](/assets/Distortion.png)  
\($$x_c,y_c$$\)是扭曲中心，r是原始图像中一点到扭曲中心的距离。

##### radial distortion

径向扭曲，具有旋转不变性，因此对x,y的修正是一样的。  
$$x_{distored} = x_{ideal}(1 + k_1 r^2 + k_2 r^4 + k_3 r^6)$$  
$$y_{distored} = y_{ideal}(1 + k_1 r^2 + k_2 r^4 + k_3 r^6)$$

##### tangential distortion

$$x_{corrected} = x + [2p_1 xy + p_2(r^2 + 2x^2)]$$  
$$y_{corrected} = y + [2p_2 xy +  p_1(r^2 + 2y^2)]$$

#####calibrateCamera
我们一般使用棋盘模型来的得到这些扭曲系数\($$k_1,k_2,k_3,p_1,p_2$$\)   
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img\_size,None,None)    
具体而言，imgpoints是真实的扭曲的图像中的点的3D坐标，objpoints是没有扭曲的棋盘坐标，是2D的，通过这两者之间，可以建立i一个映射关系，返回ret, mtx, dist, rvecs, tvecs这些参数。  
其中imgpoints可以通过OpenCV的函数来搜索到扭曲图像中的角点，ret, corners = cv2.findChessboardCorners(gray, (8,6), None)。  

