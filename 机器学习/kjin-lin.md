#K近邻
K-近邻不需要训练，因此是一种懒惰学习，急切学习(在训练时就分类)。算法的关键是度量(距离)的定义，K值得选择。如果样本很大，类别不多，每个类别样本比列比较一致，且不同类别区别比较大的时候，如果给定一个分类错误的上限$$\epsilon$$，我们没有必要遍历所有样本点找到K个近邻。因为，我们可以找到一个需要的样本上限N，N是$$\epsilon$$的函数，然后我们从总的样本中挑选出N个样本，进行K紧邻就可以巨大的减小判别的时间。  