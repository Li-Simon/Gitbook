# 拉格朗日乘子法

通过引入拉格朗日乘子，定义拉格朗日函数，通过求Lagrange函数关于原始变量的极小值来求得对偶函数。再求对偶函数关于Lagrange乘子的极大值。假设原始问题的最优解是$$\mathbf{x^*}$$,对偶问题的最优解是$$\mathbf{\lambda^*,v^*}$$，并且对偶间隙为0，则$$\mathbf{x^*, \lambda^*,v^*}$$满足如下的KKT条件。[^1]  
通过KKT条件，我们可以通过求对偶问题的解来反求原始问题的解，因为原始问题的解和对偶问题的解满足KKT条件。一个典型的例子就是SVM，在机器学习，分类问题那一节有详细介绍。

## Lagrange函数

考虑标准形式的优化问题\(4.2.1\),也称为原始问题:[^2]  
   $$\min f_0(\mathbf{x})$$  
   s.t. $$f_i\mathbf{(x) \le 0}$$, i=1,2,...,m  
   s.t. $$h_i\mathbf{(x) = 0}$$, i=1,2,...,p  
其中，自变量$$\mathbf{x} \in \mathbf{R}^n$$。问题的定义域$$D=\displaystyle \bigcap_{i=1}^{m} dom f_i \bigcap \displaystyle \bigcap_{i=1}^{p} dom h_i$$是非空集合，优化问题\(不需要保证是凸优化\)的最优值是$$p^*$$。  
Lagrange对偶的基本思想是在目标函数中考虑问题4.2.1的约束条件，即添加约束条件的加权和，得到增广的目标函数。定义问题4.2.1的Lagrange函数是$$L:\mathbf{R^n\times R^n\times R^p}->R$$:  
   $$\min L(x,\lambda,v) = f_0(x) + \displaystyle \sum_{i=1}^m \lambda_if_i(x) + \displaystyle \sum_{i=1}^p v_i h_i(x)$$  
其中定义域为$$dom L = D\times R^m\times R^p$$。$$\lambda_i$$称为第i个不等式约束$$f_i(x) \le 0$$对应的Lagrange乘子，$$v_i$$称为第i个等式约束$$h_i(x) = 0$$对应的Lagrange乘子。向量$$\mathbf{\lambda, v}$$称为对偶变量或者问题4.2.1的Lagrange乘子向量。

## Lagrange对偶函数

定义Lagrange对偶函数$$g:R^m \times R^p ->R$$为Lagrange函数关于x取得的最小值:即对$$\lambda \in R^m, v \in R^p$$，有：  
   $$g(\lambda, v) = \displaystyle  \inf_{x \in D} L(x,\lambda,v) = \displaystyle  \inf_{x \in D} (f_0(x) + \displaystyle \sum_{i=1}^m \lambda_if_i(x) + \displaystyle \sum_{i=1}^p v_i h_i(x))$$  
如果Lagrange函数关于x无下界，则对偶函数取值为$$-\infty$$。因为对偶函数是一族关于$$\lambda, v$$的仿射函数的逐点下确界，所以即使原始问题4.2.1不是凸的，对偶函数也是凹的。

## Lagrange对偶问题

通过上面定义的Lagrange函数，我们可以可以定义对偶问题。[^3]   
   maximise   $$ g(\lambda, v)$$   
   s.t. $$\lambda \ge 0, v \ge 0$$  
对于不等式约束问题，假设原始问题的最优解是$$\mathbf{x^*}$$,对偶问题的最优解是$$\mathbf{\lambda^*,v^*}$$。则$$\mathbf{x^*, \lambda^*,v^*}$$满足如下的KKT条件。  



[^1]: Steohen Boyd《凸优化》P235  

[^2]: Luenberger, 叶荫宇《线性与非线性规划》第十四章

[^3]: P.Bertsekas 《非线性规划》第三章



