# 稀疏低秩分解
##范数
### L0,L1,L1范数
L0范数表示向量中非0元素的个数。如果我们对一个矩阵加L0约束，也就是要求矩阵为0的元素越多越好。也就是希望矩阵是稀疏的。  
L1范数是指向量中各个元素绝对值之和。也称为"稀疏规则算子"(Lasso regularization)。加L1范数能实现权值稀疏。   
由于L0范数很难优化求解(NP难问题)，而且L1范数十L0范数的最优凸近似。(n=1是保证$$L^n$$范数是凸函数的最小整数)。因此一般用L1来实现稀疏性。  
参数稀疏性带来的好处就是特征选择与强的可解释性。  
L2范数叫做Ridge回归，他能防止模型过拟合，因为他尽量让$$||W||_2$$尽量小，但与L1不同，他不会让参数等于0。因为参数越小，模型越简单，因此不容易产生过拟合。  
L2好处是能防止过拟合，还可以使得条件数很多的Hessian阵优化更容易，也就是使得原来不正定的矩阵变得正定，这里的矩阵一般就是Hessian矩阵。增量拉格朗日乘子法就是这么做的，L-M算法也是这么做的。    
![](/assets/L0_L1.png)

###核范数
核范数$$||W||_*$$是指矩阵奇异值之和，英文是Nuclear Norm。它的作用就是为了实现Low-Rank(低秩)。所谓的秩就是线性方程组中独立的线性方程组数目。矩阵的秩就是矩阵的非0奇异值的个数。因此，加核范数能实现低秩矩阵。   
如下是核范数的两个应用。    
####矩阵填充
也就是推荐系统中，在User-Item矩阵中，有些用于没有购买一些items，那么我们是否该向他们推荐这些items，这在数学上是矩阵填充问题，在推荐系统中就是向从没有购买过某商品的用户推荐某商品。  
我们可以用低秩约束来实现矩阵填充，因为我们的先验是，矩阵各行(列)之间是高度相关的，因此矩阵是低秩的。  
####鲁棒PCA

