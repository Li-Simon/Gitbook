# 稀疏低秩分解

## 范数

### L0,L1,L1范数[^1]

L0范数表示向量中非0元素的个数。如果我们对一个矩阵加L0约束，也就是要求矩阵为0的元素越多越好。也就是希望矩阵是稀疏的。  
L1范数是指向量中各个元素绝对值之和。也称为"稀疏规则算子"\(Lasso regularization\)。加L1范数能实现权值稀疏。  
由于L0范数很难优化求解\(NP难问题\)，而且L1范数十L0范数的最优凸近似。\(n=1是保证$$L^n$$范数是凸函数的最小整数\)。因此一般用L1来实现稀疏性。  
参数稀疏性带来的好处就是特征选择与强的可解释性。  
L2范数叫做Ridge回归，他能防止模型过拟合，因为他尽量让$$||W||_2$$尽量小，但与L1不同，他不会让参数等于0。因为参数越小，模型越简单，因此不容易产生过拟合。  
L2好处是能防止过拟合，还可以使得条件数很多的Hessian阵优化更容易，也就是使得原来不正定的矩阵变得正定，这里的矩阵一般就是Hessian矩阵。增量拉格朗日乘子法就是这么做的，L-M算法也是这么做的。  
![](/assets/L0_L1.png)

### 核范数

核范数$$||W||_*$$是指矩阵奇异值之和，也就是迹trace，英文是Nuclear Norm。它的作用就是为了实现Low-Rank\(低秩\)。所谓的秩就是线性方程组中独立的线性方程组数目。矩阵的秩就是矩阵的非0奇异值的个数。因此，加核范数能实现低秩矩阵。对于对角矩阵，核范数就是L1范数。  
如下是核范数的两个应用。

#### 矩阵填充

也就是推荐系统中，在User-Item矩阵中，有些用于没有购买一些items，那么我们是否该向他们推荐这些items，这在数学上是矩阵填充问题，在推荐系统中就是向从没有购买过某商品的用户推荐某商品。  
我们可以用低秩约束来实现矩阵填充，因为我们的先验是，矩阵各行\(列\)之间是高度相关的，因此矩阵是低秩的。

#### 鲁棒PCA

主成分分析，可以有效的找出数据中最主要的元素和结构，去除噪声与冗余，将原来的复杂数据降维，揭露隐藏在复杂数据背后的简单结构。最简单的主成分分析就是PCA了。PCA的目的就是为了找到主元，最大程度的去除冗余和噪音的干扰。  
鲁棒主成分分析\(Robust PCA\)考虑的是这样一个问题：一般我们的数据矩阵X会包含结构信息，也包含噪声。那么我们可以将这个矩阵分解为两个矩阵，一个是低秩的\(由于内部有一定的结构信息，造成各行和各列之间是线性相关的\)，另一个是稀疏的\(由于含有噪声，而噪声是稀疏的\)。则鲁棒主成分分析可以写成以下的优化问题：  
  $$\displaystyle \min _{A,E} rank(A) + \lambda ||E||_0$$;  s.t. $$X = A + E$$  
与经典PCA问题一样，鲁棒PCA本质上也是寻找数据低维空间上的最佳投影问题。对于低秩数据观测矩阵X，假设X收到随机\(稀疏\)噪声的影响，则X的低秩就会破坏，使X变成满秩的。所以我们需要将X分解成包含其真实结构的低秩矩阵和稀疏噪声矩阵之和。为了找到低秩矩阵，实际上就找到了矩阵的本质低维空间。那有了PCA,为什么还需要有这个Robust PCA, Robust在哪？因为PCA假设我们的数据的噪声是高斯分布的，对于大的噪声或者严重的离群点，PCA就会被它影响，导致无法工作。而Robust PCA则不存在这个假设。它只是假设噪声是稀疏的，而不管噪声的强弱如何。  
由于rank和L0范数在优化上存在非凸和非光滑特性，所以我们一般将它转化成求解以下一个松弛的凸优化问题：  
  $$\displaystyle \min _{A,E} ||A||_* + \lambda ||E||_1$$;  s.t. $$X = A + E$$

说个应用吧。考虑同一副人脸的多幅图像，如果将每一副人脸图像看成是一个行向量，并将这些向量组成一个矩阵的话，那么可以肯定，理论上，这个矩阵应当是低秩的。但是，由于在实际操作中，每幅图像会受到一定程度的影响，例如遮挡，噪声，光照变化，平移等。这些干扰因素的作用可以看做是一个噪声矩阵的作用。所以我们可以把我们的同一个人脸的多个不同情况下的图片各自拉长一列，然后摆成一个矩阵，对这个矩阵进行低秩和稀疏的分解，就可以得到干净的人脸图像（低秩矩阵）和噪声的矩阵了（稀疏矩阵），例如光照，遮挡等等。至于这个的用途，你懂得。

![](/assets/robust_PCA.png)

#### 背景建模

背景建模的最简单情形是从固定摄像机的视频中分离出背景和前景。我们将视频图像序列的每一帧图像像素值拉成一个列向量，那么多个帧就是多个列向量，就组成一个观测矩阵。由于背景比较稳定，图像序列帧与帧之间具有极大的相似性，所以仅由背景像素组成的矩阵具有低秩性质。同时由于前景是移动的物体，占据的像素比列较小，故前景像素组成的矩阵具有稀疏性。视频观测矩阵就是这两种特性矩阵的叠加，因此，可以说视频背景建模实现的过程就是低秩矩阵恢复的过程。

![](/assets/background_modeling.png)

#### 变换不变低秩纹理\(TILT\)

以上介绍的是针对图像的低秩逼近算法，仅仅考虑图像样本之间像素的相似性，却没有考虑到图像作为二维的像素集合，其本身具有的规律性。事实上，对未加旋转的图像，由于图像的对称性和自相似性，我们可以将其看做事一个带噪声的低秩矩阵。当图像由端正发生旋转时，图像的对称性就会被破坏，也就是说各行像素间的线性相关性被破坏，因此矩阵的秩就会增加。  
低秩纹理映射算法\(Transform Invariant Low-Rank Textures, TILT\)是一种用低秩性与噪声的稀疏性进行低秩纹理恢复的算法。它的思想是通过几何变换$$\tau$$把D所代表的图像区域校正成正则的区域，如具有横平竖直，对称等特性，这些特性就可以通过低秩性来进行刻画。

纯背景\(众数\)+背景+前景：如有多个纯背景怎么办？  
\(群论可以排上用场了，低秩怎么与对称性建立联系？\)

![](/assets/TILT.png)

### 矩阵恢复的条件

假设从pxp矩阵中均匀随机地抽取N个元素，对于p维矩阵，秩为r,当N为多大时，就可以用如下的核范数松弛形式来精确的恢复该矩阵？  
  $$minimize ||M||_*$$，约束为： $$m_{ij}=z_{ij},(i,j)\in \Omega$$  
其中$$||M||_*$$是核范数，即M的奇异值之和。考虑到噪声，则对观测到的值直接建模并不现实，下面是一种更实际的方法：  
  $$\displaystyle \min _{M} \frac{1}{2} \displaystyle \sum_{(i,j)\in \Omega}(z_{ij}-m_{ij})^2 + \lambda ||M||_* $$

任何方法\(不仅是核范数松弛法\)都需要$$N>p\log p$$个观测值才可以准确的恢复该矩阵，即使秩为1的矩阵。  
对于给定秩为r的pxp矩阵，需要大约$$O(rp)$$个参数才能精确恢复，因为有$$O(r)$$个奇异向量，每个向量的维度是p。  
一般而言，合成和采样如果满足不等式：  
  $$N \ge Crp \log p$$  
则用核范数松弛方法精确恢复矩阵的概率很高。

#### 谱正则化[^2]

矩阵Z的低秩填充，也就是求解如下问题：  
  $$minimize rank(M)$$，约束为： $$m_{ij}=z_{ij},(i,j)\in \Omega$$  
上面是一个非凸目标函数，可以松弛为凸形式， 原子范数是矩阵秩的凸松弛：  
  $$minimize ||M||_*$$，约束为： $$m_{ij}=z_{ij},(i,j)\in \Omega$$  
上面没有考虑到噪声，考虑到噪声，则对观测到的值直接建模并不现实，下面是一种更实际的方法，是对上式得松弛版本：  
  $$\displaystyle \min _{M} \frac{1}{2} \displaystyle \sum_{(i,j)\in \Omega}(z_{ij}-m_{ij})^2 + \lambda ||M||_* $$  
这称为谱正则化。这种修改所得到的解Z并不能精确拟合观测值。但是在观测值含有噪声的情况下，这种方式能减少过拟合。  
下面介绍求解上面问题的一般过程。

##### 基于Soft-Impute的矩阵填充

首先定义几个符号，观测到的元素子集用$$\Omega$$表示，由此定义投影算子$$P_{\Omega}:\Re^{m\times n}\to \Re^{m\times n}$$为：  
  $$[P_{\Omega}(Z)]_{ij} = z_{ij}$$, if$$(i,j)\in \Omega$$  
  $$[P_{\Omega}(Z)]_{ij} = 0$$，other     
即$$P_{\Omega}$$会用0代替Z中的缺失值，只留下观测值。有了这个定义，就可以得到等式：  
  $$\displaystyle \displaystyle \sum_{(i,j)\in \Omega}(z_{ij}-m_{ij})^2 = ||P_{\Omega}(Z) - P_{\Omega}(M)||_F^2$$  
矩阵W的秩为r，则相应的奇异值分解$$W=UDV^T$$,这里定义它的软阈值化版本：  
  $$S_{\lambda}(W) = UD_{\lambda}V^T$$，其中$$D_{\lambda}=diag[(d_1-\lambda)_+,...,(d_r-\lambda)_+]$$  
Soft-Impute算法： 

1.  初始化$$Z^{old} = 0$$,创建递减的$$\lambda_1>\lambda_2>...>\lambda_k$$。
2. 对于每个k=1,2,...,K，令$$\lambda = \lambda_k$$，并进行下面的迭代，直到收敛：
   1. 计算$$\hat Z_{\lambda} \gets S_{\lambda}(P_{\Omega}(Z) + P^{+}_{\Omega}(Z^{old}))$$  
   2. 更新$$Z^{old} \gets \hat Z_{\lambda}$$  
3. 输出序列$$\hat Z_{\lambda_1},...,\hat Z_{\lambda_K}$$  

在计算中，可以通过如下分解来优化计算：  
&emsp;&emsp;$$P_{\Omega}(Z) + P^+_{\Omega}(Z^{old}) = (P_{\Omega}(Z) - P^+_{\Omega}(Z^{old})) +Z^{old}$$  
右边第一部分是稀疏的，第二部分是SVD的软阈值，是低秩的。  
可以证明，这个迭代算法能收敛到问题：  
  $$\displaystyle \min _{M\in R^{m\times n}} \frac{1}{2} ||P_{\Omega}(Z) - P_{\Omega}(M)||_F^2 + \lambda ||M||_* $$   
的解，这是目标函数的另外一种表示。  

### 终极目的

想办法把Krylov子空间用到矩阵计算上面去。  
###RIP
RIP: Restricted Isometric Property受限等容性条件。  
调和分析是下一个需要看的数学方向，因为这涉及到压缩感知这一块。 [调和分析](https://blog.csdn.net/alec1987/article/details/7511013)起源于Euler,Fourier等著名科学家的研究，主要涉及算子插值方法、极大函数方法、球调和函数理论、位势理论、奇异积分以及一般可微函数空间等。经过近200年的发展，已经成为数学中的核心学科之一，在偏微分方程、代数数论中有广泛的应用。   

[^1]: 参考 机器学习中的范数规则化之（二）核范数与规则项参数选择 [https://blog.csdn.net/zouxy09/article/details/24972869](https://blog.csdn.net/zouxy09/article/details/24972869)  
[^2]: 《稀疏统计学习及其应用》7.3  
