第一步\(一个月\)，公式推导必须会，核心思想会，并且要融会贯通。

1. SVM
2. LR，LTR
3. 决策树，RF，GBDT，xgboost
4. 贝叶斯
5. 降维：PCA, SVD
6. BP的公式推导，以及写一个简单的神经网络，并跑个小的数据。用python,numpy。
7. LeetCode上面刷Easy与Medium的题
8. 看面经，找面试常遇到的问题

第二步是最优化总结\(半个月\)，总结常用的优化算法，比如梯度下降，牛顿，拟牛顿，trust region，二次规划。

机器学习score函数设置：

1. 回归，分类，决策树，深度神经网络，图模型，概率统计，最优化方法
2. 分类，聚类，特征选择，降维等数据挖掘技术
3. 机器学习，概率统计，最优化
4. GBDT, LR，LTR, 特征提取
5. 推荐系统基本算法: LR, GBDT, SVD/SVD++, FM/FFM具体实用场景与变形
6. 对分类，回归，聚类，标注等统计机器学习问题有深入研究，熟悉常用模型：LR，KNN,Naive bayer, rf, GBDT, SVM, PCA, SVD, kmeans, kmodes等
7. 精通主流机器学习算法，对贝叶斯，随机森林，SVM，神经网络，聚类，PCA等有深入研究
8. 熟悉数据分析思路，熟悉经典的数据挖掘，机器学习算法，如：LR，决策树，BP神经网络，SVM等浅层学习，熟悉集成算法，诸如bagging, boosting,了解深度学习CNN， RNN, 熟悉使用python,了解pandas, sklearn,  xgboost
9. 熟悉常用的最优化算法设计与实现，对于非凸优化问题有深入的理解（并行模拟退火，蒙特卡洛等优化方法）
10. 机器学习算法：贝叶斯，聚类，逻辑回归，SVM，GBDT，RF

总结：

1. 分类：
   1. SVM, 
   2. LR
2. 回归：
3. 集成学习：  
   1. bagging  
   2. Boosting

4. 工具  
   1. sklearn, xgboost, tensorflow

分类总结：

1. Regression:
2. 1. Ordinary Least Squares Regression\(OLSR\)
   2. Linear Regression
   3. Logistic Regression
   4. Stepwise Regression
   5. Multivariate Adaptive Regression Spilines
   6. Locally Estimated Scatterplot Smoothing
3. Regularization Algorithms
4. 1. Ridge Regression
   2. Least Absolute Shrinkage and Selection Operator\(LASSO\)
   3. Least-Angle Regression\(LARS\)
5. Ensemble Algorithms
6. 1. Boosting
   2. Booststrapped Aggregation\(Bagging\)
   3. Adaboost
   4. Stacked Generalization\(Blending\)
   5. Gradient Boosting Machines\(GBM\)
   6. Gradient Boosted Regression Trees\(GBRT\)
   7. Random Forest
7. Decision Tree Algorithms
8. 1. Classification and Regression Tree\(CART\)
   2. Iterative Dichotomiser3\(ID3\)
   3. C4.5 and C5.0
   4. Chi-Squared Automatic Iteraction Detection\(CHAID\)
   5. Decision Stump
   6. M5
   7. Conditional Decision Trees
9. Dimensionality Reduction Algorithms
10. 1. Principle Component Analysis\(PCA\)
    2. Principle Component Regression\(PCR\)
    3. Sammon Mapping
    4. Multidimensional Scaling\(MDS\)
    5. Projection Pursuit
    6. Linear Discriminant Analysis\(LDA\)
    7. Mixture Discriminant Analysis\(MDA\)
    8. Quadratic Discriminant Analysis\(QDA\)
    9. Flexible Discriminant Analysis\(FDA\)
11. Bayesian Algorithms
12. 1. Naive Bayes
    2. Gaussian Naive Bayes
    3. Multinomial Naive Bayes
    4. Averaged One-Dependence Estimators\(AODE\) 
    5. Bayesian Belief Network\(BBN\)
    6. Bayesian Network\(BN\)
13. Clustering Algorithms
14. 1. K-Means
    2. K-Medians
    3. Expectation Maximisation\(EM\)
    4. Hierarchical
15. Instance-Based Algorithms
16. 1. K-Nearest Neighbor\(KNN\)
    2. Learning Vector Quantization\(LVQ\)
    3. Self-Organizing Map\(SOM\)
    4. Locally Weighted Learning\(LWL\)
17. Graphical Models
18. 1. Bayesian Network
    2. Markov random field
    3. Chain Graphs
    4. Ancestral Graph
19. Association Rule Learning Algorithms
20. 1. Apriori Algorithm
    2. Eclat Algorithm
    3. FP-growth



1. Deep Learning

2. 1. Deep Boltzmann Machine\(DBM\)
   2. Deep Belief Networks\(DBN\)
   3. Convolutional Neural Network\(CNN\)
   4. Stacked Auto-Encoders
3. Artificial Neural Network
4. 1. Perception
   2. Back-Propagation
   3. Radial Basis Function Network\(RBFN\)



