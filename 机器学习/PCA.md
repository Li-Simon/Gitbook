机器学习一般面对的是一个高维的问题，样本稀疏。容易面临严重的维数灾难。处理维数灾难的一个重要方法就是降维。确切的来说，对于M个数据，每个样本是N维，我们是对这个数据集张成的MxN维矩阵进行降维。这就可以用到我们在矩阵计算中的一些方法，比如主成分分析(PCA),实际上我们是通过SVD来是实现PCA的，就是取最大的K个奇异值与奇异向量。
## SVD

对于任何一个DxM的矩阵X可以做如下分解：  
$$\kern{8 em} X = UDV^T$$  
其中$$U^TU=I_D,VTV=I_N$$,D是对角矩阵。  
$$\kern{8 em} XX^T = UDV^TVDU^T=UD^2U^T$$  
$$\kern{8 em} X^TX = VDU^TUDV^T=VD^2V^T$$  
是矩阵的本征值分解。因此可以通过上面两式来求解U，V。主要用到的是矩阵本征值，本征矢求解技巧。

## PCA

我们可以通过SVD来实现PCA,具体就是只取X的SVD中的前M个其一分量。  
$$\kern{8 em} X = UDV^T \approx U_MD_MV_M^T$$  
其中$$U_M,D_M,V_M$$对于矩阵X的前M个奇异值分量。

