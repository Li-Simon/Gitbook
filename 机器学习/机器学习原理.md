#机器学习原理
##偏差，方差，噪声
偏差-方差分解可以用来对学习算法的期望泛化错误率进行拆分。同时，偏差-方差分解为我们设计模型与分析提供了一个比较清晰的方向。  
假设测试样本是$$\mathbf{x}$$，令$$\mathbf{y_D}$$为$$\mathbf{x}$$在数据集上的标记(可能存在标记错误的情况)，y为$$\mathbf{x}$$的真实标记，$$f(\mathbf{x};D)$$为训练集D上学得模型f在$$\mathbf{x}$$上的预测输出，以回归模型为例，学习算法的期望预测为：  
$$\kern{4 em} \hat f(\mathbf{x}) = E_D[f(\mathbf{x},D) ]$$  
方差是：  
$$\kern{4 em} var(\mathbf{x}) = E_D[f(\mathbf{x},D) - \hat f(\mathbf{x})]^2$$  
噪声是：
$$\kern{4 em} \epsilon ^2= E_D[y_D - y]^2$$    
输出期望与真实标记之间的差别成为偏差（Bias），即：
$$\kern{4 em} bias ^2(\mathbf{x}))= E_D[\hat f(\mathbf{x}) - y]^2$$   
为方便讨论，假设噪声的期望为0； 即：$$E_D[y_D - y] = 0$$. 下面来对模型的期望泛化误差进行分解：  
$$\kern{4 em} E(f;D) = E_D[(f(\mathbf{x},D) - y_D)^2]$$  
$$\kern{8 em} = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x})+ \hat f(\mathbf{x})- y_D)^2]$$  
$$\kern{8 em} = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y_D)2] + E_D[2(f(\mathbf{x},D) - \hat f(\mathbf{x}))(\hat f(\mathbf{x})- y_D)]$$   
$$\kern{8 em} = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y_D)^2]$$   
$$\kern{8 em} = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y + y -y_D)^2]$$   
$$\kern{8 em} = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y)^2] + E_D[(y -y_D)^2] + E_D[2(\hat f(\mathbf{x})- y)(y-y_D)]$$   
$$\kern{8 em} = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y)^2] + E_D[(y -y_D)^2] $$ 
因此就得到：
$$\kern{4 em} E(f;D)= bias^2(\mathbf{x}) + var(\mathbf{x}) + \epsilon ^2 $$ 
也就是泛化误差分成偏差，方差与噪声之和。我们设计模型分析时，可以从这三方面去考虑。  

###噪声
为了消除噪声的影响，我们需要对数据进行清洗，进行预处理。在很大程度上就是为了得到更干净的数据。  
###Bias
偏差小，说明的是模型很准，可能有过拟合的倾向，增加模型的复杂度可以使得bias减小。但是泛化能力变差，也就是variance会大，模型对数据很敏感。 如果通过多个训练模型，如果各个模型之间的关联性很小，则可以通过求平均来减小Variance，这就是集成模型中bagging系列算法做的事情，如Bagging,Random Forest.
###方差
方差小，说明模型很稳定，也就是说模型的泛化能力好，可能测试集上的数据相对于训练集来说有一些变化，但是也不影响模型的输出结果，此时，可能模型欠拟合，因此泛化能力好。这时可以通过对简单的模型进行boost，来提升模型的准确性，也就是Boost系列算法做的事情,如：AdaBoost, GBDT, XGBoost。

##最大熵原理
##奥卡姆剃刀













































































































































































































