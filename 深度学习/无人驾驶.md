# 无人驾驶

无人驾驶的主要内容：

1. 传感：通过雷达，激光，摄像头，GPS以及各种传感器来收集数据
2. 感知：通过传感收集的数据进行处理
   1. 定位
   2. 物体识别与跟踪
3. 决策：基于数据做出决策
   1. 行为预测
   2. 路径规划
   3. 避障

## 感知

### 物体识别

无人驾驶，首先就是就是定位问题，要知道自己在哪儿，让自己处于安全的区域内，因此，首先就是需要检测马路上的斑马线。

#### 线检测

##### Hough变换

直线检测最经典的方法就是Hough变换，Hough变换在图像处理那一章节已经介绍了，因此这笔不介绍原理了。主要介绍OpenCV中的HoughLinesP函数：  
C++: void HoughLinesP\(InputArray image, OutputArray lines, double rho, double theta, int threshold, double minLineLength=0, double maxLineGap=0 \)  
Parameters:  
image – 8-bit, single-channel binary source image. The image may be modified by the function.  
lines – Output vector of lines. Each line is represented by a 4-element vector  \($$x_1, y_1, x_2, y_2$$\) , where  $$(x_1,y_1)$$ and  $$(x_2, y_2)$$ are the ending points of each detected line segment.  
rho – Distance resolution of the accumulator in pixels.  
theta – Angle resolution of the accumulator in radians.  
threshold – Accumulator threshold parameter. Only those lines are returned that get enough votes \( &gt;hreshold\).  
minLineLength – Minimum line length. Line segments shorter than that are rejected.  
maxLineGap – Maximum allowed gap between points on the same line to link them.  
例子：  
rho = 2  \# distance resolution in pixels of the Hough grid  
theta = np.pi / 180  \# angular resolution in radians of the Hough grid  
threshold = 12  \# minimum number of votes \(intersections in Hough grid cell\)  
min\_line\_length = 200  \# minimum number of pixels making up a line  
max\_line\_gap = 200  \# maximum gap in pixels between connectable line segments

##### Canny edge dector

C++: void Canny\(InputArray image, OutputArray edges, double threshold1, double threshold2, int apertureSize=3, bool L2gradient=false\)  
Parameters:  
image – single-channel 8-bit input image.  
edges – output edge map; it has the same size and type as image.  
threshold1 – first threshold for the hysteresis procedure.  
threshold2 – second threshold for the hysteresis procedure.  
apertureSize – aperture size for the Sobel\(\) operator.  
L2gradient – a flag, indicating whether a more accurate  $$L_2 norm  =\sqrt{(dI/dx)^2 + (dI/dy)^2}$$ should be used to calculate the image gradient magnitude \( L2gradient=true \), or whether the default  $$ L_1 norm  =|dI/dx|+|dI/dy|  $$is enough \( L2gradient=false \).

#### Distortion 与 Calibrating Camera

To ensure that the geometrical shape of objects is represented consistently, no matter where they appear in an image.  
![](/assets/Distortion.png)  
\($$x_c,y_c$$\)是扭曲中心，r是原始图像中一点到扭曲中心的距离。

##### radial distortion

径向扭曲，具有旋转不变性，因此对x,y的修正是一样的。  
$$x_{distored} = x_{ideal}(1 + k_1 r^2 + k_2 r^4 + k_3 r^6)$$  
$$y_{distored} = y_{ideal}(1 + k_1 r^2 + k_2 r^4 + k_3 r^6)$$

##### tangential distortion

$$x_{corrected} = x + [2p_1 xy + p_2(r^2 + 2x^2)]$$  
$$y_{corrected} = y + [2p_2 xy +  p_1(r^2 + 2y^2)]$$

##### calibrateCamera

To computer the transformation between 3D object points in the world and 2D image points  
我们一般使用棋盘模型来的得到这些扭曲系数\($$k_1,k_2,k_3,p_1,p_2$$\)  
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera\(objpoints, imgpoints, img\_size,None,None\), 其中mtx is camera matrix, mtx, dist is distortion coefficients. 具体而言，imgpoints是真实的扭曲的图像中的点的3D坐标，objpoints是没有扭曲的棋盘坐标，是2D的，通过这两者之间，可以建立i一个映射关系，返回ret, mtx, dist, rvecs, tvecs这些参数。  
其中imgpoints可以通过OpenCV的函数来搜索到扭曲图像中的角点，ret, corners = cv2.findChessboardCorners\(gray, \(8,6\), None\)。  
再用dst = cv2.undistort\(img, mtx, dist, None, mtx\)就可以恢复图像了。

#### Perspective Transform

To transform an image such that we are effectively viewing objects from adifferent angle or direction.

```py
offset = 100 # offset for dst points
# Grab the image shape
img_size = (gray.shape[1], gray.shape[0])

# For source points I'm grabbing the outer four detected corners
src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])
# For destination points, I'm arbitrarily choosing some points to be
# a nice fit for displaying our warped result 
# again, not exact, but close enough for our purposes
dst = np.float32([[offset, offset], [img_size[0]-offset, offset], [img_size[0]-offset, img_size[1]-offset], 
                                     [offset, img_size[1]-offset]])
# Given src and dst points, calculate the perspective transform matrix
M = cv2.getPerspectiveTransform(src, dst)
# Warp the image using OpenCV warpPerspective()
warped = cv2.warpPerspective(undist, M, img_size)
```

注意dst中对应于src中的四点可以任意，getPerspectiveTransform中注意参数顺序。

### Sobel

```py
gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)
sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)
# Calculate the gradient magnitude
gradmag = np.sqrt(sobelx**2 + sobely**2)
# Rescale to 8 bit
scale_factor = np.max(gradmag)/255 
gradmag = (gradmag/scale_factor).astype(np.uint8) 
binary_output = np.zeros_like(gradmag)
binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1
```

**HSV**

color space \(hue, saturation, and value\), and

**HLS**

space \(hue, lightness, and saturation\).  
 S channel相对于其它channel(R,G,B,L,h,v)对于阈值分割更robust。  

