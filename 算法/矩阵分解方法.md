# 矩阵分解方法

1. Schur分解

2. LU分解

3. QR分解

4. 矩阵本征值分解

5. 矩阵奇异值分解

6. Krylov子空间法

7. Cholesky 分解

## Schur分解

复nxn的矩阵酉相似于一个上三角阵。  
&emsp;&emsp;$$  A = QUQ^{-1}$$  
其中Q是酉矩阵\(Unitary Matrix\).

## LU分解

知道存在LU分解，能用来进行线性方程组求解以及矩阵求逆就可以，具体的实现细节可以查书，比如《Matrix Computations》3.2节 THe LU Factorization。明白其思想更好。  
任何非奇异方阵都可以分解成上三角阵与下三角阵之积

$$\begin{bmatrix}a_{11}&a_{12}&\cdots&a_{1n}\\ a_{21}&a_{22}&\cdots&a_{2n}\\\cdots&\cdots&\cdots&\cdots\\a_{n1}&a_{n2}&\cdots&a_{nn}\end{bmatrix} = 
\begin{bmatrix}l_{11}&0&\cdots&0\\ l_{21}&l_{22}&\cdots&0\\\cdots&\cdots&\cdots&\cdots\\l_{n1}&l_{n2}&\cdots&l_{nn}\end{bmatrix}*
\begin{bmatrix}u_{11}&u_{12}&\cdots&u_{1n}\\ 0&u_{22}&\cdots&a_{2n}\\\cdots&\cdots&\cdots&\cdots\\0&0&\cdots&u_{nn}\end{bmatrix}$$  
对比两边矩阵的，可以求得：  
但是编程时，行列都是从0开始时，要注意转换。  
第1行：$$a_{1j} = u_{1j}, j = 1, 2,..,n. => u_{1j} = a_{1j}$$。  
第1列：$$a_{j1} = l_{j1}u_{11}, j = 1, 2,..,n. => l_{j1} = a_{j1}/u_{11}$$。  
...。  
第k行：$$a_{kj} = \sum_{i=1}^{i=k} l_{ki}u_{ij}, => u_{kj} = a_{kj} - \sum_{i=1}^{i=k-1} l_{ki}u_{ij}$$。  
第k列：$$a_{jk} = \sum_{i=1}^{i=k} l_{ji}u_{ik}, => u_{jk} = [a_{jk} - \sum_{i=1}^{i=k-1} l_{ji}u_{ik}]/u_{kk}$$。

因为前k-1行的$$u_{ij}$$都已知，前k-1列的$$l_{ij}$$都已知,因此可以求得第k行$$u_{ij}$$，第k列的$$l_{ij}$$。  
问题：得保证$$a_{11}$$非0，以及矩阵非奇异。

### 利用LU分解求线性方程组的解

求解线性方程组 Ax=b相当于求解LUx=b;  
设Y = UX; 因此LY = b;首先求解LY = b,  
$$\begin{bmatrix}l_{11}&0&\cdots&0\\ l_{21}&l_{22}&\cdots&0\\\cdots&\cdots&\cdots&\cdots\\l_{n1}&l_{n2}&\cdots&l_{nn}\end{bmatrix}\begin{bmatrix}y_{1}\\y_{2}\\\cdots&\\y_{n}\end{bmatrix}= 
\begin{bmatrix}b_{1}\\b_{2}\\\cdots&\\b_{n}\end{bmatrix}$$  
求解上面的方程：  
第1行：$$y_{1} = b_{1}$$。  
对于第k行：$$b_{k} = \sum_{i=1}^{i=k}l_{ki}y_{i} =>y_{k} = b_{k} - \sum_{i=1}^{i=k-1}l_{ki}y_{i}$$。  
求得Y之后，代入Y=UX求得X:  
$$\begin{bmatrix}u_{11}&u_{12}&\cdots&u_{1n}\\ 0&u_{22}&\cdots&u_{2n}\\\cdots&\cdots&\cdots&\cdots\\0&0&\cdots&u_{nn}\end{bmatrix}\begin{bmatrix}x_{1}\\x_{2}\\\cdots&\\x_{n}\end{bmatrix}= 
\begin{bmatrix}y_{1}\\y_{2}\\\cdots&\\y_{n}\end{bmatrix}$$  
对于上三角矩阵，我们从第n行开始求解  
对第n行：$$y_{n} = u_{nn}x_{n} => x_{n} = y_{n}/u_{nn}$$。  
...。  
对第k行：$$y_{k} = \sum_{i=k}^{i=n}u_{ki}x_{i} => x_{k} = [y_{n}-\sum_{i=k+1}^{i=n}u_{ki}x_{i}]/u_{kk}$$  
这样通过LU分解矩阵就求得了线性方程组的就X.

## 矩阵求逆

我们可以利用LU分解来求非奇异方阵的逆矩阵。  
**AB=I**  
$$\begin{bmatrix}a_{11}&a_{12}&\cdots&a_{1n}\\ a_{21}&a_{22}&\cdots&a_{2n}\\\cdots&\cdots&\cdots&\cdots\\a_{n1}&a_{n2}&\cdots&a_{nn}\end{bmatrix}*
\begin{bmatrix}b_{11}&b_{12}&\cdots&b_{1n}\\ b_{21}&b_{22}&\cdots&b_{2n}\\\cdots&\cdots&\cdots&\cdots\\b_{n1}&b_{n2}&\cdots&b_{nn}\end{bmatrix}=
\begin{bmatrix}1&0&\cdots&0\\ 0&1&\cdots&1\\\cdots&\cdots&\cdots&\cdots\\0&0&\cdots&u_{nn}\end{bmatrix}$$  
可以分解成求:  
$$\begin{bmatrix}a_{11}&a_{12}&\cdots&a_{1n}\\ a_{21}&a_{22}&\cdots&a_{2n}\\\cdots&\cdots&\cdots&\cdots\\a_{n1}&a_{n2}&\cdots&a_{nn}\end{bmatrix}*
\begin{bmatrix}b_{1k}\\b_{2k}\\\cdots\\b_{nk}\end{bmatrix}=
\begin{bmatrix}0\\0\\\cdots\\1\\\cdots\\0\end{bmatrix}$$  
右边的列，就只是第k行值非0；  
$$A*b_{k} = e_{k}$$,对所有的$$e_{k}$$求出$$b_{k}$$就可以得到A的逆矩阵$$A^{-1} = B$$  
实际求解中把A 换成LU来减少计算量。总的计算开销还是$$n^{3}$$。但是这样并不比直接的高斯消元法来的快。

算法实现如下。

```cpp
//LU
template<class T>
void CMatrix<T>::LU(CMatrix &mat, int N, CMatrix* L, CMatrix* U)
{
    for (int k = 0; k <N; k++)
    {
        for (int j = k; j<N;j++)
        {
            T U_k_j = mat.Get(k, j);
            T L_j_k = mat.Get(j, k);
            for (int i = 0; i <k; i++)
            {
                U_k_j -= L->Get(k, i)*U->Get(i, j);
            }
            U->Set(k, j, U_k_j);

            for (int i = 0; i < k; i++)
            {
                L_j_k -= L->Get(j, i)*U->Get(i, k);
            }
            L_j_k = L_j_k / U->Get(k, k);
            L->Set(j, k, L_j_k);

        }
    }
}

//solve linear algebra equations
CVector Solve(CMatrix<double>& mat, CVector& vec)
{
    CVector X(vec.Size());
    CVector Y(vec.Size());
    if (mat.Columns() != mat.Rows() && mat.Rows() != vec.Size())
    {
        printf("Dimension not match!");
        return X;
    }
    CMatrix<double> L(vec.Size(), vec.Size());
    CMatrix<double> U(vec.Size(), vec.Size());
    mat.LU(mat, vec.Size(), &L, &U);
    Y = SolveLow(L, vec);
    cout << "Y\n" << Y;
    X = SolveUpper(U, Y);
    cout << "X\n" << X;
    return X;
}

CVector SolveLow(CMatrix<double>& mat, CVector& vec)
{
    CVector vecRes(vec.Size());
    if (mat.Columns() != mat.Rows() && mat.Rows() != vec.Size())
    {
        printf("Dimension not match!");
        return vecRes;
    }

    for (int k = 0; k < vec.Size(); k++)
    {
        double mRes = 0;
        mRes = vec.Get(k);
        for (int i = 0; i < k; i++)
        {
            mRes -= mat.Get(k, i)*vecRes.Get(i);
        }
        vecRes.Set(k, mRes);
    }
    return vecRes;
}

CVector SolveUpper(CMatrix<double>& mat, CVector& vec)
{
    CVector vecRes(vec.Size());
    if (mat.Columns() != mat.Rows() && mat.Rows() != vec.Size())
    {
        printf("Dimension not match!");
        return vecRes;
    }

    for (int k = vec.Size() -1; k >=0 ; k--)
    {
        double mRes = 0;
        mRes = vec.Get(k);
        for (int i = k+1; i <vec.Size(); i++)
        {
            mRes -= mat.Get(k, i)*vecRes.Get(i);
        }
        mRes = mRes / mat.Get(k, k);
        vecRes.Set(k, mRes);
    }
    return vecRes;
}

//inverse matrix
template<class T>
CMatrix<T>  CMatrix<T>::Inv()
{
    CMatrix result = *this;
    CMatrix<double> L(mRows, mColumns);
    CMatrix<double> U(mRows, mColumns);
    CMatrix<double> InvMat(mRows, mColumns);
    LU(result,mRows, &L, &U);
    for (int col = 0; col < mColumns; col++)
    {
        CVector vec(mRows, col);
        CVector mSolution(mRows);
        mSolution = SolveLow(L, vec);
        mSolution = SolveUpper(U, mSolution);
        for (int row = 0; row<mRows; row++)
        {
            InvMat.Set(row, col, mSolution.Get(row));
        }
    }
    return InvMat;
}
```

## QR分解

定理：设A是mxn阶矩阵，m&gt;=n,假设A为满秩的，则存在一个唯一的正交矩阵$$Q (Q^{T}Q=I)$$和唯一的具有正对角元$$r_{ij}>0$$的nxn阶上三角阵$$R$$使得 $$A=QR$$.    
QR分解算法:    
&emsp;&emsp;$$A_0 = A = Q_1R_1$$  
然后：  
&emsp;&emsp;$$ A_1 = R_1Q_1$$  
一般形式：  
&emsp;&emsp;$$ A_k = R_kQ_k$$  
&emsp;&emsp;$$A_k = Q_{k+1}R_{k+1}$$  
因此有：  
&emsp;&emsp;$$ A_k = Q_{k+1}R_{k+1} = Q_{k+1}A_{k+1}Q_{k+1}^T$$  
因此：  
&emsp;&emsp;$$A = Q_1R_1 = Q_1(A_1Q_1^T) = Q_1A_1Q_1^T$$  
&emsp;&emsp;&emsp;$$  = (Q_1Q_2...Q_k)A_k(Q_1Q_2...Q_k)^T$$  
当K区域无穷时，$$A_k$$就是对称矩阵，$$(Q_1Q_2...Q_k)$$就是本征矢量。  
算法的收敛性：假设：  
&emsp;&emsp;$$|\lambda_1| > |\lambda_2| >...>|\lambda_n|$$  
则矩阵$$A_k$$的矩阵元$$a_{ij}^{(k)}$$将以如下方式收敛到0:  
&emsp;&emsp;$$a_{ij}^{(k)} = O(|\lambda_i / \lambda_j|^{k})$$  for all i&gt;j.

### python QR分解实例

发现随着QR迭代次数的增加，与原矩阵A相似的矩阵$$A^{k}$$越来越收敛于上三角矩阵，也就是对角元以下的元素越来越趋于0，但是对角元上面的元素并不趋于0。虽然$$A^{k}$$并没有趋于一个对角阵，但是$$(Q_1Q_2...Q_k)$$就是本征矢。这给你我们QR分解求解矩阵本征值一个直观的图像。  
![](/assets/QR_Python.png)

### 缺点：

每步QR分解的时间复杂度是$$O(n^3)$$，此外当有简并的本征值时，收敛会非常慢。

### 更有效的QR分解：Hessenberg矩阵

基于直接的QR分解并不是高效的方法，如果通过Household变换或者Givens变换把待分解的矩阵变换成上Hessenberg矩阵，此操作的时间复杂度是$$O(n^3)$$，此时再利用GIvens变换来进行QR分解，则QR分解的复杂度从$$O(n^3)$$变成了$$O(n^2)$$。  
问题是为啥不直接一步用Household变换实现QR？反正时间复杂度都是$$O(n^3)$$？  
原因是，当我们把矩阵变成Hessenberg矩阵后，以后就不再需要进行$$O(n^3)$$的操作，因为上三角乘以上Hessenberg矩阵还是上Hessenberg矩阵，也就是所有的$$A^{k}$$都是上Hessenberg矩阵。因此，以后的QR分解都在Hessenberg上进行，每次的复杂度都是$$O(n^2)$$.

![](/assets/Hessenberg_QR.png)

### QR分解方式的比较

QR分解的实现方式有三种，第一种通过Gram-Schmidt正交化方法，第二种是Household变换方法，第三种是Givens变换方法。

| QR分解方法 | 时间复杂度 | 优缺点 |
| :--- | :--- | :--- |
| Gram-Schmidt正交化方法 |  |  |
| Household变换 |  |  |
| Givens变换 |  | 可以并行。适合于稀疏矩阵 |
| Hessenberg+Givens | 一次Household进行QR分解的时间 | 时间复杂度最小 |

## 矩阵本征值分解

要证明的是，可以通过矩阵QR分解来实现矩阵本征值分解。  
实际上，我们在求解矩阵的本征值的时候，要分矩阵是对称矩阵还是非对称矩阵，或者说是厄密矩阵还是非厄密矩阵。
算法的收敛性：假设：  
$$|\lambda_1| > |\lambda_2| >...>|\lambda_n|$$  
则矩阵$$A_k$$的矩阵元$$a_{ij}^{(k)}$$将以如下方式收敛到0:  
$$a_{ij}^{(k)} = O(|\lambda_i / \lambda_j|^{k})$$  for all i&gt;j. 
也就是对角元以下的矩阵元会以这样的方式收敛到0。  

##Krylov子空间法
为了求解如下线性方程组问题：  
&emsp;&emsp;$$\mathbf{Ax=b}$$  
身处大数据时代，为了更高效的处理数据，从大数据中提取我们想要的知识，我们就不得不提到Krylov子空间法，这个方法的强大之处在于我们不需要在超大的原始空间求解问题，而是在一个远小于原始空间的子空间去求解问题。适合对称矩阵的共轭梯度法，Lanczos方法，以及适合非对称矩阵的Arnodi算法就是Krylov子空间法的实例。要明白的就是，要求一个矩阵本征值，我们还是需要使用正交变换，就是寻找一个正交矩阵Q对矩阵A进行变换，使得A变成一个上Hessenberg矩阵，再如果这个上Hessenberg矩阵有一个下次对角元$$h_{k,k-1} = 0$$，我们就可以对矩阵进行分解，只需要求$$H_{k\times k}$$即可得到原始矩阵A的本征值。  
对一个$$n\times n$$的矩阵，最便宜的操作摸过于让他乘以一个向量。即：我们可以得到如下序列：  
&emsp;&emsp;$$\mathbf{y_1=b}$$    
&emsp;&emsp;$$\mathbf{y_2=Ay_1}$$   
&emsp;&emsp;$$\mathbf{y_3=Ay_2=A^2y_1}$$   
&emsp;&emsp;$$\mathbf{y_n=Ay_{n-1}=A^{n-1}y_1}$$   
定义：$$K = (\mathbf{y_1,y_2,...,y_n})$$  
&emsp;&emsp;$$AK = (\mathbf{y_2,y_3,...,Ay_n}) = \mathbf{(y_2,...,y_n,A^ny_1)}$$  
假定:$$\mathbf{AK = KC}$$  
我们可以得到C的形式如下：  
$$K^{-1}AK=C=
\begin{bmatrix}0&0&\cdots&-c_1\\ 1&0&\cdots&-c_2\\0&1&\cdots&-c_3\\\cdots&\cdots&\cdots&\cdots\\0&\cdots&1&-c_{n-1}\\0&0&\cdots&-c_n\end{bmatrix}$$  
C是一个上海森堡矩阵。  
一个问题是，即使A是稀疏的，K也可能是稠密的；另外一个问题是，由于执行的是矩阵的幂操作，因此$$y_i$$最终收敛到A的最大本征值对应的本征矢量方向。因此我们需要一些正交化技巧，也就是对厄密矩阵，有Lanczos方法，对一般矩阵有Arnoldi方法。    
实际上，我们用一个正交矩阵Q来近似K,对K做QR分解， K=QR。因此有：  
&emsp;&emsp;$$K^{-1}AK = (R^{-1}Q^T)AQR = C$$  
&emsp;&emsp;$$Q^TAQ = K^{-1}AK = RCR^{-1} = H$$   
因为R是上三角矩阵，C是上Hessenberg矩阵，因此H是上Hessenberg矩阵。 
又因为： AQ=QH。  
&emsp;&emsp;$$Aq_j = \displaystyle \sum_{i=1}^{j+1}h_{i,j}q_i$$   
因为$$q_i$$是正交的，因此我们可以在上式同时乘以$$q_m^T$$,然后得到：    
&emsp;&emsp;$$q_m^TAq_j = \displaystyle \sum_{i=1}^{j+1}h_{i,j}q_m^Tq_i = h_{m,j}$$  for $$1 \le m \le j$$   
因此:  
&emsp;&emsp;$$h_{j+1,j}q_{j+1} = Aq_j - \displaystyle \sum_{i=1}^{j}h_{i,j}q_i$$   
总的来说，我们想对矩阵A做正交变换，因为正交变换不改变矩阵的本征值。因此，我们需要求这个正交变换矩阵Q。下面的算法告诉我们怎么求这个正交矩阵Q。附带我们把正交变换后得到的矩阵H也求出来了，H是一个上Hessenberg矩阵。因此如果我们发现H有一个下次对角元为$$h_{k,k-1}$$，则我们就可以停止迭代，因为此时我们可以对矩阵H进行分解，因为我们得到的矩阵$$H_{1:k,1:k}$$的矩阵本征值就是原始矩阵的H的本征值，    
因此有如下的:
###Arnoldi算法：  
$$q_1 = b/||b||_2$$    
/*k is the number of columns of Q and H to computer*/   
for j=1 to k:   
&emsp;$$z = Aq_j$$    
&emsp;for i = 1 to j:   
&emsp;&emsp;$$h_{i,j} = q_i^Tz$$    
&emsp;&emsp;$$z = z - h_{i,j}q_i$$     
&emsp; end for  
&emsp;$$h_{j+1,j} = ||z||_2$$      
&emsp;if $$h_{j+1,j} = 0$$, quit   
&emsp;$$q_{j+1} = z/h_{j+1,j}$$   
end for   
$$q_j$$成为Arnoldi矢量。时间复杂度是$$O(k^2n)$$，k是子空间大小。在这里，每一步迭代用到$$z = Aq_j$$,这是为了对Krylov子空间进行正交化的方式。Q是原始Krylov子空间$$K_k(A,b) =(b,Ab,A^2b,...,A^{k-1}b)$$正交化之后的空间。   
###对称情况的Krylov
如果A是对称的，则H是上Hessenberg矩阵，也是对称矩阵，因此是三对角矩阵。假设T=H。  
&emsp;&emsp;&emsp;&emsp;$$T=
\begin{bmatrix}\alpha_1&\beta_1&\cdots&0\\ \beta_1&\alpha_2&\cdots&0\\0&\beta_2&\cdots&0\\\cdots&\cdots&\cdots&\cdots\\0&0&\cdots&\alpha_n\end{bmatrix}$$   
AQ=QT，计算第j列。得到：  
&emsp;$$Aq_{j} = \beta_{j-1}q_{j-1}+\alpha_jq_j+\beta_{j}q_{j+1}$$   
因为$$q_j$$彼此A共轭，因此上式两边同城$$q_j$$得到：$$q_jAq_j=\alpha_j$$。  
对于对称情况，我们有如下的Lanczos算法。  
###Lanczos算法
$$q_1 = b/||b||_2,\beta_0 = 0, q_0 = 0$$      
/*k is the number of columns of Q and H to computer*/   
for j=1 to k:   
&emsp;$$z = Aq_j$$    
&emsp;$$\alpha_j = q_j^Tz$$  
&emsp;$$z = z - \alpha_jq_j - \beta_{j-1}q_{j-1}$$  
&emsp;$$\beta_j = ||z||_2$$  
&emsp;if $$\beta_j = 0$$, quit   
&emsp;$$q_{j+1} = z/\beta_j$$   
end for  
$$q_j$$称为Lanczos矢量。 
###Krylov子空间
定义：Krylov子空间$$K_k(A,b)$$为$$(b,Ab,A^2b,...,A^{k-1}b)$$   
###Krylov方法求解线性方程组
我们讨论Krylov方法的目的是通过k步就可以求解线性方程组AX=b。  
#####共轭梯度法
定理：A是对称矩阵，$$T_k=Q_k^TAQ_k$$,并且$$r_k=b-Ax_k,x_k\in K_k$$,如果$$T_k$$是非奇异的，并且$$x_k = Q_kT_k^{-1}e_1||b||_2$$,这里$$e_1^{k\times 1} = [1,0,...,0]^T$$,因此$$Q_k^Tr_k=0$$。  
如果A也是正定的，则$$T_k$$一定不是奇异的，并且$$x_k$$也最小化$$||r_k||_{A^{-1}}$$，在所有的$$x_k\in K_k$$。此外$$r_k=||r_k||_2q_{k+1}$$。  
CG迭代只需要保留三个向量$$x_k,r_k= b - Ax_k$$，以及共轭梯度$$p_k$$。通过如下方式迭代$$x_k=x_{k+1}+vp_k$$。  
####共轭梯度算法
对任意初始点$$\mathbf{x_0}\in E^n$$,定义$$\mathbf{d_0=-g_0=b-Qx_0}$$  
&emsp;&emsp;$$\mathbf{x_{k+1}}=\mathbf{x_k}+\alpha_k \mathbf{d_k}$$  
&emsp;&emsp;$$\alpha_k = -\mathbf{\frac{g_k^Td_k}{d_k^TQd_k}}$$  
&emsp;&emsp;$$\mathbf{d_{k+1}}=-\mathbf{g_{k+1}}+\beta_k \mathbf{d_k}$$   
&emsp;&emsp;$$\beta_k = -\mathbf{\frac{g_{k+1}^TQd_k}{d_{k+1}^TQd_k}}$$ 
其中$$\mathbf{g_k = Qx_k - b}$$


[^1] [A first course in linear algebra](http://linear.ups.edu/)

