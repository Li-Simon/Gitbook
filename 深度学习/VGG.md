## VGG

相对于以前的网络而言，VGG与GoogLeNet的网络变得更深了。VGGNet在整个网络中使用3x3的小感受野，以步长1进行逐像素卷积，因此两个3x3卷积相当于一个5x5,三个3x3卷积核相当于一个7x7的卷积核，这样大大减小了模型的参数个数。  使用了小尺寸的卷积核，增加了网络深度并不会带来明显的参数膨胀，却能在更深的网络中获得更高的精度。

#### VGG结构

![](/assets/VGG_structure.png)  
VGG16包含16层，VGG19包含19层。一系列的VGG在最后三层的全连接层上完全一样，整体结构上都包含5组卷积层，卷积层之后跟一个MaxPool。所不同的是5组卷积层中包含的级联的卷积层越来越多。

#### VGG11-VGG19

![](/assets/VGG_11_19.png)

#### 图像大小变化

AlexNet中每层卷积层中只包含一个卷积，卷积核的大小是7_7,。在VGGNet中每层卷积层中包含2~4个卷积操作，卷积核的大小是3_3，卷积步长是1，池化核是2\*2，步长为2,。VGGNet最明显的改进就是降低了卷积核的尺寸，增加了卷积的层数。  
![](/assets/VGG_Structure.png)

### 原理

1. VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）。  
比如用2个3x3代替一个5x5  
![](/assets/VGG_small_kernel_replace_large.png)
1. VGG的多尺度训练   
   VGGNet使用了Multi-Scale的方法做数据增强，将原始图像缩放到不同尺寸S，然后再随机裁切224′224的图片，这样能增加很多数据量，对于防止模型过拟合有很不错的效果。实践中，作者令S在\[256,512\]这个区间内取值，使用Multi-Scale获得多个版本的数据，并将多个版本的数据合在一起进行训练。VGG作者在尝试使用LRN之后认为LRN的作用不大，还导致了内存消耗和计算时间增加[^1]。  



[^1]:  VGGNet网络结构  https://blog.csdn.net/dcrmg/article/details/79254654

