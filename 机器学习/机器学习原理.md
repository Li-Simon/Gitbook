# 机器学习原理
机器学习可以从多种视角去分析，比如从最优化视角，概率视角，贝叶斯视角等。本书尽力以最优化的视角来考虑机器学习问题与算法，当然，本书还远不近完善，还在升级迭代的过程中。当前是尽力理解这三种视角的有点与局限性，也就是这三种方法的边界，以及与机器学习的交集，而后形成自己的认知。       
##模型分析 
任何有监督的学习都可以通过偏差，方差，噪声来对模型进行分析。通过减小这三个指标中任何一项(除噪声，因为这是数据本身的问题，garbage in, garbage out)，都能提高模型的准确性。最典型的就是基于Bagging类方法能降低方差，基于Boosting类方法能降低偏差。  
Bagging适合于High Variance & Low Bias 的模型。  
Boosting适合于High Bias& Low Variance 的模型。
## 偏差，方差，噪声

偏差-方差分解可以用来对学习算法的期望泛化错误率进行拆分。同时，偏差-方差分解为我们设计模型与分析提供了一个比较清晰的方向。  
假设测试样本是$$\mathbf{x}$$，令$$\mathbf{y_D}$$为$$\mathbf{x}$$在数据集上的标记\(可能存在标记错误的情况\)，y为$$\mathbf{x}$$的真实标记，$$f(\mathbf{x};D)$$为训练集D上学得模型f在$$\mathbf{x}$$上的预测输出，以回归模型为例，学习算法的期望预测为：  
&emsp;&emsp;$$\hat f(\mathbf{x}) = E_D[f(\mathbf{x},D) ]$$  
方差是：  
&emsp;&emsp;$$var(\mathbf{x}) = E_D[f(\mathbf{x},D) - \hat f(\mathbf{x})]^2$$  
噪声是：  
&emsp;&emsp;$$ \epsilon ^2= E_D[y_D - y]^2$$  
输出期望与真实标记之间的差别成为偏差（Bias），即：  
&emsp;&emsp;$$ bias ^2(\mathbf{x}))= E_D[\hat f(\mathbf{x}) - y]^2$$  
为方便讨论，假设噪声的期望为0； 即：$$E_D[y_D - y] = 0$$. 下面来对模型的期望泛化误差进行分解：  
&emsp;&emsp;$$E(f;D) = E_D[(f(\mathbf{x},D) - y_D)^2]$$    
&emsp;&emsp;&emsp;&emsp;&emsp;$$= E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x})+ \hat f(\mathbf{x})- y_D)^2]$$      
&emsp;&emsp;&emsp;&emsp;&emsp;$$ = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y_D)2] + E_D[2(f(\mathbf{x},D) - \hat f(\mathbf{x}))(\hat f(\mathbf{x})- y_D)]$$    
&emsp;&emsp;&emsp;&emsp;&emsp;$$ = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y_D)^2]$$    
&emsp;&emsp;&emsp;&emsp;&emsp;$$ = E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y + y -y_D)^2]$$    
&emsp;&emsp;&emsp;&emsp;&emsp;$$= E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y)^2] + E_D[(y -y_D)^2] + E_D[2(\hat f(\mathbf{x})- y)(y-y_D)]$$    
&emsp;&emsp;&emsp;&emsp;&emsp;$$= E_D[(f(\mathbf{x},D) - \hat f(\mathbf{x}))^2]+ E_D[(\hat f(\mathbf{x})- y)^2] + E_D[(y -y_D)^2] $$  
因此就得到：  
&emsp;&emsp;$$ E(f;D)= bias^2(\mathbf{x}) + var(\mathbf{x}) + \epsilon ^2 $$  
也就是泛化误差分成偏差，方差与噪声之和。我们设计模型分析时，可以从这三方面去考虑。

### 噪声

为了消除噪声的影响，我们需要对数据进行清洗，进行预处理。在很大程度上就是为了得到更干净的数据。

### Bias

偏差小，说明的是模型很准，可能有过拟合的倾向，增加模型的复杂度可以使得bias减小。但是泛化能力变差，也就是variance会大，模型对数据很敏感。 如果模型bias大，可以通过对简单的模型进行boost，来提升模型的准确性，也就是Boost系列算法做的事情,如：AdaBoost, GBDT, XGBoost。

### 方差

方差小，说明模型很稳定，也就是说模型的泛化能力好，可能测试集上的数据相对于训练集来说有一些变化，但是也不影响模型的输出结果，此时，可能模型欠拟合，因此泛化能力好，最典型的就是决策树桩，它的方差小，但是是欠拟合的。如果模型variance大，  
可以通过训练多个模型，并让各个模型之间的关联性很小，通过求平均来减小Variance，这就是集成模型中bagging系列算法做的事情，如Bagging,Random Forest.

## 最大似然函数

输入：$$X \in R^n$$  
输出： $$Y \in (1,2,...,K)$$  
条件概率：  $$P(X=x|Y=C_k) = P(X^{(1)} = x^{(1)},X^{(2)} = x^{(2)},...,X^{(n)} = x^{(n)}|Y=C_k)$$,  k=1,2,...,K  
假设有N个样本点$$(X_i,Y_i), i=1,2,...,N$$  
条件概率： $$P(Y=y|X=x,\mathbf{\theta})$$，其中$$\mathbf{\theta}$$是模型的参数。  
似然函数定义为：每个样本点发生概率的乘积：  
&emsp;&emsp;$$L(\mathbf{\theta}) = \displaystyle \prod _{n=1}^NP(Y=Y_n|X=X_n,\mathbf{\theta})$$  
我们需要求得一个模型，使得在所有样本点在该模型发生的几率极大，几率是联合几率，是每个样本发生几率的乘积。也就是极大化似然函数。  
分类与回归问题似乎都可以转化成求解似然函数。

### 用极大似然函数求解回归问题

输入：$$\mathbf{X} \in R^n$$  
输出： $$Y \in R$$  
我们的模型是$$f(\mathbf{X}, \mathbf{\Theta})$$,其中$$\mathbf{\Theta}$$是模型参数，X是输入变量。  
假设我们的损失函数是平方误差，因此我们的cost function可以表示如下：  
&emsp;&emsp;$$\ L(\mathbf{X},\mathbf{\Theta}) = \frac{1}{2}\displaystyle \sum _{n=1}^N(f(X_n, \mathbf{\Theta}) - Y_n)^2$$  
等价于：  
&emsp;&emsp;$$ e^{L(\mathbf{X},\mathbf{\Theta})}= e^{\displaystyle \prod _{n=1}^N \frac{1}{2}(f(X_n, \mathbf{\Theta}) - Y_n)^2} = \displaystyle \prod _{n=1}^Ne^{ \frac{1}{2}(f(X_n, \mathbf{\Theta}) - Y_n)^2}$$  
实际上，最小化$$L(\mathbf{X},\mathbf{\Theta})$$等价于最小化$$e^{L(\mathbf{X},\mathbf{\Theta})}$$,等价于最大化$$e^{-L(\mathbf{X},\mathbf{\Theta})}$$,也就是等价于最大化  
&emsp;&emsp;$$\Gamma(\Theta) = \displaystyle \prod _{n=1}^Ne^{ -\frac{1}{2}(f(X_n, \mathbf{\Theta}) - Y_n)^2} = \displaystyle \prod _{n=1}^N P(X_n, \Theta)$$  
其中  
&emsp;&emsp;$$ P(X_n, \Theta) = e^{ -\frac{1}{2}(f(X_n, \mathbf{\Theta}) - Y_n)^2}$$  
定义成回归模型中样本$$(X_n, Y_n)$$发生的几率，这样我们就把回归问题与几率联系起来了。我们把求解损失函数最小，转化成极大化似然函数的求解。  
对于不同的损失函数，我们都可以转化成对应的概率。  
对于分类问题，怎么用一个统一的框架来解析？可以是基于概率的。

### 用极大似然函数求解多类分类问题

在这里我们以多项逻辑斯蒂回归为例，讨论怎么用最大化似然函数来求解这一类问题。  
假设离散性随机变量Y的取值是\(1,2,...,K\),输入变量$$\mathbf{X} \in R^n$$  
则，模型如下：  
&emsp;&emsp;$$ P(Y=k|x) = \frac{exp(\mathbf{w_k}\mathbf{x})}{1+\displaystyle \sum_{k=1}^{K-1}exp(\mathbf{w_k}\mathbf{x})}, k=1,2,...,K-1$$  
&emsp;&emsp;$$ P(Y=K|x) = \frac{1}{1+\displaystyle \sum_{k=1}^{K-1}exp(\mathbf{w_k}\mathbf{x})}$$  
这里$$\mathbf{x} \in \mathbf{R^{n+1}};\mathbf{w_k} \in \mathbf{R^{n+1}}$$.  
因此，总的似然函数可以表示为：  
&emsp;&emsp;$$L(\mathbf{W}) = \displaystyle \prod _{n=1}^NP(Y=Y_n|X=X_n)$$  
这样，我们需要求的参数是$$W = (\mathbf{w_1},\mathbf{w_2},...,\mathbf{w_{n+1}})$$.

### 用极大似然与SVM来做多类分类问题

核心，定义出到超平面的距离，每一个类，一个超平面，然后定义距离，然后转化成概率，最终转化成极大似然函数求解。不过已经有了基于逻辑回归与极大似然来求解多分类的问题，因此已经建立起基于极大似然来解释分类与回归的问题，故是否还有必要基于极大似然与SVM来做多分类问题？其实没有必要。  

###麦克斯韦妖与信息熵
不存在一个监测系统，能区分粒子的速度而对粒子做出区分，使得原本温度相同的系统，自发的形成高温与低温子系统。因为在区分例子速度时，就是一个信息处理的过程，使得系统的信息熵减小。那么，怎么根据熵增原理，确定系统的熵减数量与检测系统需要付出的信息熵的数量，或者能量。  
## 最大熵原理


## 极大似然与最大熵原理的等价性
对有限个状态的问题，可以建立起极大似然与最大熵原理之间的联系。推广到连续状态问题，先处理一维问题。假设后验分布是$$P(\mathbf{x|\theta})$$ 
根据最大熵原理，需要满足：  
&emsp;&emsp;$$E(\mathbf{\theta}) = -\int P(\mathbf{x|\theta})\ln P(\mathbf{x|\theta})$$  
&emsp;&emsp;$$\mathbf{\theta} = \arg \max_{\mathbf{\theta}} E(\mathbf{\theta})$$    
需要加上这一节。  
## 奥卡姆剃刀

### Evaluation Metrics

二分类： AUC，  
多分类： 交叉熵\(log loss\)  
回归： 均方差  
For any kind of machine learning problem, we must know how we are going to evaluate our results, or what the evaluation metric or objective is. For example in case of a skewed binary classification problem we generally choose area under the receiver operating characteristic curve \(ROC AUC or simply AUC\). In case of multi-label or multi-class classification problems, we generally choose categorical cross-entropy or multiclass log loss and mean squared error in case of regression problems.

## No FREE Lunch定理，先验，正则化

### NO FREE LUNCH

![](/assets/NO_FREE_LUNCH.png)  
黑点是训练样本，白点是测试样本点。根据训练样本，我们得到模型A，B。如果测试点不同，则A，B的相对表现不同。问题的关键在于，我们先验的假设了\(测试\)样本点在所有空间是均匀分布的，因此，在训练集上训练出的所有模型的效果是一样的，因为你总有样本集是落在你模型预测的曲线之上的。  
因此，如果样本点在整个数据空间是均匀分布的前提下，则不存在一个模型或算法在所有问题上比其它算法更优越。  
但是现实遇到的问题是，数据的分布是受限制的，数据存在一个先验分布，因此会存在一些模型比其它模型更有效。这里NFL不再有是因为问题的前提--数据是均匀分布的--不再成立。因此，脱离场景谈方法是无效的，我们只能针对特定的问题，寻找最佳的优化方法。

### 正则化

没有免费的午餐定理告诉我们没有一个模型是对所有的样本是最优的[^1]，因此，对于特定的样本，我们需要把先验加进模型中\(也就是损失函数中\)，这个先验就是我们对这个样本的知识，比如样本数据的分布，样本的均值或者方差等\(统计物理学中的系统的能量可以看成一种均值，统计物理学中有很多启发性的模型\)。加到模型中的就是我们的正则项，正则项就是一个先验，是我们需要模型满足的约束。  
一个问题是，正则化只能使我们的模型更稳定，不会更精确，那先验怎么作为正则化的形式加进模型，使得我们的模型更优越呢？  
### 先验分布与熵值。
没有先验知识，样本在参数空间是均匀分布的，因此熵值很大；如果有强的先验，因此样本局限在参数空间的特定区域，因此系统具有的熵值比较小。  
### 先验分布与损失函数。

知道预测误差的先验分布，才能选择合适的损失函数。知其然，才能知其所以然。  
交叉熵  
平方损失：  
0-1损失：分类问题，  
Log损失：  
Hinge损失：  
指数损失：  
平方损失：等价于误差服从高斯分布的极大似然估计。适用于回归问题。  
麦哈顿距离损失等价于误差服从拉普拉斯分布的极大似然估计。  
0-1损失相当于误差分从  
数据的误差的先验分布\(统计学派观点？\)：  极大似然  
模型参数的先验分布\(贝叶斯观点\)：正则化是模型复杂度的惩罚函数，真理是美的，简洁的。 你可以自己定义模型的复杂度？问题是怎么定义模型复杂度？\(正则化是要求模型参数只能在0附近，但是现实可能是，真实的模型参数不在0附件，贝叶斯观点并不能与模型参数误差的先验分布联系起来，因为正则化假定模型参数的均值皆为0，但是贝叶斯观点并不要求这样。\)

| 损失函数 | 预测误差的先验分布 |
| :--- | :--- |
| 平方损失 | 高斯分布 |
| 曼哈顿距离损失 | 拉普拉斯分布 |
| 0-1损失 | 二项分布 |



[^1]: Ian Goodfellow 《deep learning》

