# 第六章 最优化方法

这章主要讨论常见的非线性最优化方法，以及优化技巧与不同方法的优缺点。

最优化算法的分类方式有多种，从应用的泰勒展开的阶数来说，可分为一阶算法与二阶算法；从搜索的策略来讲，可以分为方向固定的线性搜索算法与步长固定的Trust Region method；就解决的问题而言，有凸优化算法与非凸优化算法。对凸优化问题而言，由于局部极小就是全局最小，因此通过梯度下降方法就可以很好的解决。大多数我们面对的是非凸优化问题，存在大量的局部极小值，我们也不需要得到全局最小值，只需要求得一个较好的局部极小值就可以了，因为局部极小值对应的解是稳定的，就可能是一个满足系统要求的解。  
思考这一章该怎么去写？但是得先回答以下两个问题，你写这一章的目的是什么？你想把它写成什么样子？答案不能独立于问题而存在，答案与问题是一对，\[Key,Value\],且一个key可以对于与多个value。因此，首先来介绍写这一章的目的。  
$$\kern{2 em}$$数值最优化方法也可以按照求解的问题来说，有带约束的非线性优化问题，带约束的非线性优化问题\(非线性优化是相对于线性规划而言的，除了线性规划以外的优化问题称为非线性优化问题\)。因此优化问题可以分为如下三类：

## 1. 线性规划

线性规划暂时不讲，因为现在主要讨论非线性优化问题，此外可以通过平方把线性优化问题转化为非线性优化问题，一个例子就是求解线性方程组问题转化为最小二乘问题。

## 2. 无约束非线性优化问题

一维搜索问题，包含二分法，弦割法，牛顿法,\(黄金分割法\)这些也不重用，因此主要讨论如下几种算法。

### 梯度下降法

### 牛顿法

#### L-M\(Levenberg-Marquardt\)算法

#### DogLeg算法

### 拟牛顿法

### 共轭梯度法

## 3. 带约束非线性优化问题

原则就是通过拉格朗日乘子法把等式约束，用KKT乘子法把不等式约束问题转化为无约束优化问题来求解，这样可以利用无约束优化问题来求解。

### 等式约束的拉格朗日乘子法

### 不等式约束的KKT乘子法

1. 局部极小算法
   1. 一阶方法
      1. SGD
      2. Mini-batch SGD
   2. 二阶方法
      1. 牛顿法
      2. 拟牛顿法
         1. BFGS
         2. DFP
         3. Brody类方法
   3. Trust Region method
      1. L-M算法
      2. DogLeg算法
   4. 线性搜索法
   5. 凸优化
   6. 非凸优化
2. 全局最小算法
   1. 模拟退火
   2. 遗传算法

## 需要做的事情

1. 把最前沿的非凸优化，比如ADMM算法加进来
2. 分布式机器学习中应用的优化算法要有清晰的轮廓，以及她与单机机器学习系统中的优化算法有啥区别。因此，是否有必要加一个section，关于分布式机器学习优化方法？
3. 运筹学，线性规划，非线性规划里面处理的基本东西要在你的脑海中有一个基本的印象。

[^1]

[^1]: 刘铁岩 《分布式机器学习--算法，理论与实战》

